{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コーパス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n"
     ]
    }
   ],
   "source": [
    "# 文章を単語に分割する\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "words = text.split(' ')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "# 単語にIDを振る\n",
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id) # 0, 1, 2, ...\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word\n",
    "\n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語のリストを単語IDのリストに変換する\n",
    "import numpy as np\n",
    "\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 処理をまとめる\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id) # 0, 1, 2, ...\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "    \n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    \n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6 7]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '': 6, '.': 7}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '', 7: '.'}\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共起行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "from utills import preprocess\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "            \n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "    \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / np.sqrt(np.sum(x**2) + eps) # xの正規化\n",
    "    ny = y / np.sqrt(np.sum(y**2) + eps) # yの正規化\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = create_co_matrix(corpus, len(word_to_id))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(C, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067758832467"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity(C[word_to_id['you']], C[word_to_id['i']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    # 1. クエリを取り出す\n",
    "    if query not in word_to_id:\n",
    "        print('%s is not found' % query)\n",
    "        return\n",
    "    \n",
    "    print('\\n[query]' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # 2. コサイン類似度の算出\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "    \n",
    "    # 3. コサイン類似度の結果から、その値を高い順に出力\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        \n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query]you\n",
      " goodbye: 0.7071067758832467\n",
      " i: 0.7071067758832467\n",
      " hello: 0.7071067758832467\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100 + 1) == 0:\n",
    "                    print('%.1f%% done' % (100*cnt/total))\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "    N = corpus.shape[0]\n",
    "    if corpus.ndim == 1:\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
    "        for idx, word_id in enumerate(corpus):\n",
    "            one_hot[idx, word_id] = 1\n",
    "        \n",
    "    elif corpus.ndim == 2:\n",
    "        C = corpus.shape[1]\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "        for idx_0, word_ids in enumerate(corpus):\n",
    "            for idx_1, word_id in enumerate(word_ids):\n",
    "                one_hot[idx_0, idx_1, word_id] = 1\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec：CBOW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW：コンテキストからターゲットを予測するモデル　例：「私は[　]を食べる」の[カレー]を予測する  \n",
    "Skip-gram：ターゲットからコンテキストを予測するモデル　例：[カレー]から「私は[　]を食べる」を予測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33224865  0.56697273 -0.45356309]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]]) # (1, 7)\n",
    "W = np.random.randn(7, 3) # (7, 3)\n",
    "h = np.dot(c, W) # (1, 7)x(7, 3) = (1, 3)\n",
    "\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, window_size=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.in_layer = nn.Linear(vocab_size, hidden_size, bias=False)\n",
    "        self.out_layer = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, contexts):\n",
    "        # contexts: (batch_size, window_size*2, vocab_size)\n",
    "        h = torch.zeros(contexts.size(0), self.hidden_size) # (batch_size, hidden_size)\n",
    "        for i in range(self.window_size*2):\n",
    "            h += self.in_layer(contexts[:, i, :])\n",
    "        h /= self.window_size*2 # 平均を取る\n",
    "        out = self.out_layer(h) # (batch_size, vocab_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 7])\n",
      "tensor([[ 0.0043, -0.0468, -0.0348,  0.0580, -0.0608, -0.0202,  0.0303],\n",
      "        [ 0.0633, -0.0432,  0.0186,  0.0801, -0.0777, -0.0477,  0.1536]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cbow = CBOW(7, 3).to(device)\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
    "c2 = np.array([[0, 0, 0, 0, 0, 1, 0]])\n",
    "c3 = np.array([[0, 1, 0, 0, 0, 0, 0]])\n",
    "C1 = np.array([c0, c1])\n",
    "C2 = np.array([c2, c3])\n",
    "C = np.array([C1, C2])\n",
    "C = torch.tensor(C, dtype=torch.float32).to(device)\n",
    "C = C.view(-1, 2, 7)\n",
    "\n",
    "print(C.shape)\n",
    "\n",
    "h = cbow(C)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2], [1, 3], [2, 4], [3, 1], [4, 5], [1, 6]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utills import preprocess, create_co_matrix\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "contexts = []\n",
    "target = []\n",
    "\n",
    "for i in range(1, len(corpus)-1):\n",
    "    target.append(corpus[i])\n",
    "    contexts.append([corpus[i-1], corpus[i+1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "def create_contexts_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "    \n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size+1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx+t])\n",
    "        contexts.append(cs)\n",
    "    \n",
    "    return np.array(contexts), np.array(target)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "print(contexts)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "    N = corpus.shape[0]\n",
    "    if corpus.ndim == 1:\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
    "        for idx, word_id in enumerate(corpus):\n",
    "            one_hot[idx, word_id] = 1\n",
    "        \n",
    "    elif corpus.ndim == 2:\n",
    "        C = corpus.shape[1]\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "        for idx_0, word_ids in enumerate(corpus):\n",
    "            for idx_1, word_id in enumerate(word_ids):\n",
    "                one_hot[idx_0, idx_1, word_id] = 1\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "contexts = convert_one_hot(contexts, len(word_to_id))\n",
    "target = convert_one_hot(target, len(word_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = torch.tensor(contexts, dtype=torch.float32).to(device)\n",
    "target = torch.tensor(target, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.8746\n",
      "Epoch: 2, Loss: 3.5888\n",
      "Epoch: 3, Loss: 3.2485\n",
      "Epoch: 4, Loss: 2.7568\n",
      "Epoch: 5, Loss: 2.2844\n",
      "Epoch: 6, Loss: 1.9327\n",
      "Epoch: 7, Loss: 1.6298\n",
      "Epoch: 8, Loss: 1.4773\n",
      "Epoch: 9, Loss: 1.3244\n",
      "Epoch: 10, Loss: 1.2105\n",
      "Epoch: 11, Loss: 1.1218\n",
      "Epoch: 12, Loss: 1.0907\n",
      "Epoch: 13, Loss: 1.0384\n",
      "Epoch: 14, Loss: 0.9674\n",
      "Epoch: 15, Loss: 0.9015\n",
      "Epoch: 16, Loss: 0.8679\n",
      "Epoch: 17, Loss: 0.7714\n",
      "Epoch: 18, Loss: 0.7568\n",
      "Epoch: 19, Loss: 0.6910\n",
      "Epoch: 20, Loss: 0.6448\n",
      "Epoch: 21, Loss: 0.5805\n",
      "Epoch: 22, Loss: 0.5431\n",
      "Epoch: 23, Loss: 0.5707\n",
      "Epoch: 24, Loss: 0.5554\n",
      "Epoch: 25, Loss: 0.5486\n",
      "Epoch: 26, Loss: 0.4923\n",
      "Epoch: 27, Loss: 0.4834\n",
      "Epoch: 28, Loss: 0.4897\n",
      "Epoch: 29, Loss: 0.4760\n",
      "Epoch: 30, Loss: 0.5093\n",
      "Epoch: 31, Loss: 0.5046\n",
      "Epoch: 32, Loss: 0.4986\n",
      "Epoch: 33, Loss: 0.4711\n",
      "Epoch: 34, Loss: 0.4933\n",
      "Epoch: 35, Loss: 0.4947\n",
      "Epoch: 36, Loss: 0.4913\n",
      "Epoch: 37, Loss: 0.4930\n",
      "Epoch: 38, Loss: 0.4878\n",
      "Epoch: 39, Loss: 0.4689\n",
      "Epoch: 40, Loss: 0.4920\n",
      "Epoch: 41, Loss: 0.4891\n",
      "Epoch: 42, Loss: 0.4947\n",
      "Epoch: 43, Loss: 0.4909\n",
      "Epoch: 44, Loss: 0.4869\n",
      "Epoch: 45, Loss: 0.4675\n",
      "Epoch: 46, Loss: 0.4872\n",
      "Epoch: 47, Loss: 0.4846\n",
      "Epoch: 48, Loss: 0.4812\n",
      "Epoch: 49, Loss: 0.4972\n",
      "Epoch: 50, Loss: 0.4677\n",
      "Epoch: 51, Loss: 0.4681\n",
      "Epoch: 52, Loss: 0.4889\n",
      "Epoch: 53, Loss: 0.4706\n",
      "Epoch: 54, Loss: 0.4691\n",
      "Epoch: 55, Loss: 0.4771\n",
      "Epoch: 56, Loss: 0.4667\n",
      "Epoch: 57, Loss: 0.4947\n",
      "Epoch: 58, Loss: 0.4864\n",
      "Epoch: 59, Loss: 0.4679\n",
      "Epoch: 60, Loss: 0.4846\n",
      "Epoch: 61, Loss: 0.4691\n",
      "Epoch: 62, Loss: 0.4927\n",
      "Epoch: 63, Loss: 0.4898\n",
      "Epoch: 64, Loss: 0.4884\n",
      "Epoch: 65, Loss: 0.4665\n",
      "Epoch: 66, Loss: 0.4814\n",
      "Epoch: 67, Loss: 0.4790\n",
      "Epoch: 68, Loss: 0.4662\n",
      "Epoch: 69, Loss: 0.4656\n",
      "Epoch: 70, Loss: 0.4769\n",
      "Epoch: 71, Loss: 0.4655\n",
      "Epoch: 72, Loss: 0.4669\n",
      "Epoch: 73, Loss: 0.4674\n",
      "Epoch: 74, Loss: 0.4670\n",
      "Epoch: 75, Loss: 0.4882\n",
      "Epoch: 76, Loss: 0.4652\n",
      "Epoch: 77, Loss: 0.4652\n",
      "Epoch: 78, Loss: 0.4840\n",
      "Epoch: 79, Loss: 0.4815\n",
      "Epoch: 80, Loss: 0.4663\n",
      "Epoch: 81, Loss: 0.4758\n",
      "Epoch: 82, Loss: 0.4736\n",
      "Epoch: 83, Loss: 0.4720\n",
      "Epoch: 84, Loss: 0.4713\n",
      "Epoch: 85, Loss: 0.4715\n",
      "Epoch: 86, Loss: 0.4649\n",
      "Epoch: 87, Loss: 0.4943\n",
      "Epoch: 88, Loss: 0.4922\n",
      "Epoch: 89, Loss: 0.4761\n",
      "Epoch: 90, Loss: 0.4746\n",
      "Epoch: 91, Loss: 0.4979\n",
      "Epoch: 92, Loss: 0.4939\n",
      "Epoch: 93, Loss: 0.4711\n",
      "Epoch: 94, Loss: 0.4707\n",
      "Epoch: 95, Loss: 0.4810\n",
      "Epoch: 96, Loss: 0.4758\n",
      "Epoch: 97, Loss: 0.4678\n",
      "Epoch: 98, Loss: 0.4683\n",
      "Epoch: 99, Loss: 0.4936\n",
      "Epoch: 100, Loss: 0.4710\n",
      "Epoch: 101, Loss: 0.4717\n",
      "Epoch: 102, Loss: 0.4700\n",
      "Epoch: 103, Loss: 0.4684\n",
      "Epoch: 104, Loss: 0.4889\n",
      "Epoch: 105, Loss: 0.4756\n",
      "Epoch: 106, Loss: 0.4650\n",
      "Epoch: 107, Loss: 0.4841\n",
      "Epoch: 108, Loss: 0.4676\n",
      "Epoch: 109, Loss: 0.4846\n",
      "Epoch: 110, Loss: 0.4646\n",
      "Epoch: 111, Loss: 0.4818\n",
      "Epoch: 112, Loss: 0.4653\n",
      "Epoch: 113, Loss: 0.4822\n",
      "Epoch: 114, Loss: 0.4792\n",
      "Epoch: 115, Loss: 0.4646\n",
      "Epoch: 116, Loss: 0.4819\n",
      "Epoch: 117, Loss: 0.4800\n",
      "Epoch: 118, Loss: 0.4839\n",
      "Epoch: 119, Loss: 0.4644\n",
      "Epoch: 120, Loss: 0.4644\n",
      "Epoch: 121, Loss: 0.4780\n",
      "Epoch: 122, Loss: 0.4820\n",
      "Epoch: 123, Loss: 0.4801\n",
      "Epoch: 124, Loss: 0.4781\n",
      "Epoch: 125, Loss: 0.4867\n",
      "Epoch: 126, Loss: 0.4833\n",
      "Epoch: 127, Loss: 0.4778\n",
      "Epoch: 128, Loss: 0.4805\n",
      "Epoch: 129, Loss: 0.4787\n",
      "Epoch: 130, Loss: 0.4763\n",
      "Epoch: 131, Loss: 0.4871\n",
      "Epoch: 132, Loss: 0.4835\n",
      "Epoch: 133, Loss: 0.4654\n",
      "Epoch: 134, Loss: 0.4658\n",
      "Epoch: 135, Loss: 0.4797\n",
      "Epoch: 136, Loss: 0.4645\n",
      "Epoch: 137, Loss: 0.4769\n",
      "Epoch: 138, Loss: 0.4647\n",
      "Epoch: 139, Loss: 0.4805\n",
      "Epoch: 140, Loss: 0.4645\n",
      "Epoch: 141, Loss: 0.4779\n",
      "Epoch: 142, Loss: 0.4763\n",
      "Epoch: 143, Loss: 0.4654\n",
      "Epoch: 144, Loss: 0.4833\n",
      "Epoch: 145, Loss: 0.4741\n",
      "Epoch: 146, Loss: 0.4734\n",
      "Epoch: 147, Loss: 0.4817\n",
      "Epoch: 148, Loss: 0.4649\n",
      "Epoch: 149, Loss: 0.4651\n",
      "Epoch: 150, Loss: 0.4789\n",
      "Epoch: 151, Loss: 0.4640\n",
      "Epoch: 152, Loss: 0.4767\n",
      "Epoch: 153, Loss: 0.4753\n",
      "Epoch: 154, Loss: 0.4645\n",
      "Epoch: 155, Loss: 0.4728\n",
      "Epoch: 156, Loss: 0.4715\n",
      "Epoch: 157, Loss: 0.4703\n",
      "Epoch: 158, Loss: 0.4638\n",
      "Epoch: 159, Loss: 0.4642\n",
      "Epoch: 160, Loss: 0.4651\n",
      "Epoch: 161, Loss: 0.4656\n",
      "Epoch: 162, Loss: 0.4792\n",
      "Epoch: 163, Loss: 0.4640\n",
      "Epoch: 164, Loss: 0.4639\n",
      "Epoch: 165, Loss: 0.4761\n",
      "Epoch: 166, Loss: 0.4745\n",
      "Epoch: 167, Loss: 0.4647\n",
      "Epoch: 168, Loss: 0.4830\n",
      "Epoch: 169, Loss: 0.4812\n",
      "Epoch: 170, Loss: 0.4806\n",
      "Epoch: 171, Loss: 0.4767\n",
      "Epoch: 172, Loss: 0.4817\n",
      "Epoch: 173, Loss: 0.4741\n",
      "Epoch: 174, Loss: 0.4805\n",
      "Epoch: 175, Loss: 0.4748\n",
      "Epoch: 176, Loss: 0.4738\n",
      "Epoch: 177, Loss: 0.4728\n",
      "Epoch: 178, Loss: 0.4638\n",
      "Epoch: 179, Loss: 0.4721\n",
      "Epoch: 180, Loss: 0.4638\n",
      "Epoch: 181, Loss: 0.4801\n",
      "Epoch: 182, Loss: 0.4786\n",
      "Epoch: 183, Loss: 0.4768\n",
      "Epoch: 184, Loss: 0.4740\n",
      "Epoch: 185, Loss: 0.4658\n",
      "Epoch: 186, Loss: 0.4841\n",
      "Epoch: 187, Loss: 0.4815\n",
      "Epoch: 188, Loss: 0.4756\n",
      "Epoch: 189, Loss: 0.4780\n",
      "Epoch: 190, Loss: 0.4666\n",
      "Epoch: 191, Loss: 0.4739\n",
      "Epoch: 192, Loss: 0.4653\n",
      "Epoch: 193, Loss: 0.4808\n",
      "Epoch: 194, Loss: 0.4714\n",
      "Epoch: 195, Loss: 0.4640\n",
      "Epoch: 196, Loss: 0.4643\n",
      "Epoch: 197, Loss: 0.4773\n",
      "Epoch: 198, Loss: 0.4657\n",
      "Epoch: 199, Loss: 0.4779\n",
      "Epoch: 200, Loss: 0.4762\n",
      "Epoch: 201, Loss: 0.4749\n",
      "Epoch: 202, Loss: 0.4643\n",
      "Epoch: 203, Loss: 0.4774\n",
      "Epoch: 204, Loss: 0.4638\n",
      "Epoch: 205, Loss: 0.4756\n",
      "Epoch: 206, Loss: 0.4765\n",
      "Epoch: 207, Loss: 0.4637\n",
      "Epoch: 208, Loss: 0.4752\n",
      "Epoch: 209, Loss: 0.4639\n",
      "Epoch: 210, Loss: 0.4637\n",
      "Epoch: 211, Loss: 0.4636\n",
      "Epoch: 212, Loss: 0.4737\n",
      "Epoch: 213, Loss: 0.4727\n",
      "Epoch: 214, Loss: 0.4637\n",
      "Epoch: 215, Loss: 0.4635\n",
      "Epoch: 216, Loss: 0.4720\n",
      "Epoch: 217, Loss: 0.4789\n",
      "Epoch: 218, Loss: 0.4641\n",
      "Epoch: 219, Loss: 0.4756\n",
      "Epoch: 220, Loss: 0.4759\n",
      "Epoch: 221, Loss: 0.4745\n",
      "Epoch: 222, Loss: 0.4644\n",
      "Epoch: 223, Loss: 0.4794\n",
      "Epoch: 224, Loss: 0.4774\n",
      "Epoch: 225, Loss: 0.4643\n",
      "Epoch: 226, Loss: 0.4641\n",
      "Epoch: 227, Loss: 0.4767\n",
      "Epoch: 228, Loss: 0.4742\n",
      "Epoch: 229, Loss: 0.4731\n",
      "Epoch: 230, Loss: 0.4719\n",
      "Epoch: 231, Loss: 0.4642\n",
      "Epoch: 232, Loss: 0.4635\n",
      "Epoch: 233, Loss: 0.4706\n",
      "Epoch: 234, Loss: 0.4634\n",
      "Epoch: 235, Loss: 0.4714\n",
      "Epoch: 236, Loss: 0.4634\n",
      "Epoch: 237, Loss: 0.4637\n",
      "Epoch: 238, Loss: 0.4769\n",
      "Epoch: 239, Loss: 0.4755\n",
      "Epoch: 240, Loss: 0.4809\n",
      "Epoch: 241, Loss: 0.4637\n",
      "Epoch: 242, Loss: 0.4633\n",
      "Epoch: 243, Loss: 0.4772\n",
      "Epoch: 244, Loss: 0.4759\n",
      "Epoch: 245, Loss: 0.4781\n",
      "Epoch: 246, Loss: 0.4761\n",
      "Epoch: 247, Loss: 0.4747\n",
      "Epoch: 248, Loss: 0.4734\n",
      "Epoch: 249, Loss: 0.4721\n",
      "Epoch: 250, Loss: 0.4705\n",
      "Epoch: 251, Loss: 0.4689\n",
      "Epoch: 252, Loss: 0.4812\n",
      "Epoch: 253, Loss: 0.4636\n",
      "Epoch: 254, Loss: 0.4781\n",
      "Epoch: 255, Loss: 0.4660\n",
      "Epoch: 256, Loss: 0.4657\n",
      "Epoch: 257, Loss: 0.4771\n",
      "Epoch: 258, Loss: 0.4638\n",
      "Epoch: 259, Loss: 0.4637\n",
      "Epoch: 260, Loss: 0.4751\n",
      "Epoch: 261, Loss: 0.4734\n",
      "Epoch: 262, Loss: 0.4744\n",
      "Epoch: 263, Loss: 0.4733\n",
      "Epoch: 264, Loss: 0.4644\n",
      "Epoch: 265, Loss: 0.4713\n",
      "Epoch: 266, Loss: 0.4641\n",
      "Epoch: 267, Loss: 0.4698\n",
      "Epoch: 268, Loss: 0.4780\n",
      "Epoch: 269, Loss: 0.4711\n",
      "Epoch: 270, Loss: 0.4708\n",
      "Epoch: 271, Loss: 0.4635\n",
      "Epoch: 272, Loss: 0.4758\n",
      "Epoch: 273, Loss: 0.4747\n",
      "Epoch: 274, Loss: 0.4733\n",
      "Epoch: 275, Loss: 0.4797\n",
      "Epoch: 276, Loss: 0.4770\n",
      "Epoch: 277, Loss: 0.4636\n",
      "Epoch: 278, Loss: 0.4638\n",
      "Epoch: 279, Loss: 0.4729\n",
      "Epoch: 280, Loss: 0.4635\n",
      "Epoch: 281, Loss: 0.4635\n",
      "Epoch: 282, Loss: 0.4729\n",
      "Epoch: 283, Loss: 0.4742\n",
      "Epoch: 284, Loss: 0.4731\n",
      "Epoch: 285, Loss: 0.4640\n",
      "Epoch: 286, Loss: 0.4713\n",
      "Epoch: 287, Loss: 0.4637\n",
      "Epoch: 288, Loss: 0.4633\n",
      "Epoch: 289, Loss: 0.4761\n",
      "Epoch: 290, Loss: 0.4749\n",
      "Epoch: 291, Loss: 0.4646\n",
      "Epoch: 292, Loss: 0.4643\n",
      "Epoch: 293, Loss: 0.4763\n",
      "Epoch: 294, Loss: 0.4632\n",
      "Epoch: 295, Loss: 0.4633\n",
      "Epoch: 296, Loss: 0.4741\n",
      "Epoch: 297, Loss: 0.4749\n",
      "Epoch: 298, Loss: 0.4632\n",
      "Epoch: 299, Loss: 0.4728\n",
      "Epoch: 300, Loss: 0.4752\n",
      "Epoch: 301, Loss: 0.4632\n",
      "Epoch: 302, Loss: 0.4632\n",
      "Epoch: 303, Loss: 0.4632\n",
      "Epoch: 304, Loss: 0.4632\n",
      "Epoch: 305, Loss: 0.4737\n",
      "Epoch: 306, Loss: 0.4727\n",
      "Epoch: 307, Loss: 0.4760\n",
      "Epoch: 308, Loss: 0.4745\n",
      "Epoch: 309, Loss: 0.4740\n",
      "Epoch: 310, Loss: 0.4735\n",
      "Epoch: 311, Loss: 0.4744\n",
      "Epoch: 312, Loss: 0.4731\n",
      "Epoch: 313, Loss: 0.4721\n",
      "Epoch: 314, Loss: 0.4758\n",
      "Epoch: 315, Loss: 0.4711\n",
      "Epoch: 316, Loss: 0.4750\n",
      "Epoch: 317, Loss: 0.4635\n",
      "Epoch: 318, Loss: 0.4732\n",
      "Epoch: 319, Loss: 0.4721\n",
      "Epoch: 320, Loss: 0.4646\n",
      "Epoch: 321, Loss: 0.4759\n",
      "Epoch: 322, Loss: 0.4634\n",
      "Epoch: 323, Loss: 0.4739\n",
      "Epoch: 324, Loss: 0.4729\n",
      "Epoch: 325, Loss: 0.4753\n",
      "Epoch: 326, Loss: 0.4636\n",
      "Epoch: 327, Loss: 0.4709\n",
      "Epoch: 328, Loss: 0.4748\n",
      "Epoch: 329, Loss: 0.4634\n",
      "Epoch: 330, Loss: 0.4732\n",
      "Epoch: 331, Loss: 0.4734\n",
      "Epoch: 332, Loss: 0.4721\n",
      "Epoch: 333, Loss: 0.4738\n",
      "Epoch: 334, Loss: 0.4634\n",
      "Epoch: 335, Loss: 0.4726\n",
      "Epoch: 336, Loss: 0.4635\n",
      "Epoch: 337, Loss: 0.4732\n",
      "Epoch: 338, Loss: 0.4722\n",
      "Epoch: 339, Loss: 0.4735\n",
      "Epoch: 340, Loss: 0.4633\n",
      "Epoch: 341, Loss: 0.4724\n",
      "Epoch: 342, Loss: 0.4634\n",
      "Epoch: 343, Loss: 0.4734\n",
      "Epoch: 344, Loss: 0.4632\n",
      "Epoch: 345, Loss: 0.4723\n",
      "Epoch: 346, Loss: 0.4632\n",
      "Epoch: 347, Loss: 0.4732\n",
      "Epoch: 348, Loss: 0.4727\n",
      "Epoch: 349, Loss: 0.4718\n",
      "Epoch: 350, Loss: 0.4633\n",
      "Epoch: 351, Loss: 0.4631\n",
      "Epoch: 352, Loss: 0.4708\n",
      "Epoch: 353, Loss: 0.4748\n",
      "Epoch: 354, Loss: 0.4714\n",
      "Epoch: 355, Loss: 0.4631\n",
      "Epoch: 356, Loss: 0.4736\n",
      "Epoch: 357, Loss: 0.4726\n",
      "Epoch: 358, Loss: 0.4714\n",
      "Epoch: 359, Loss: 0.4701\n",
      "Epoch: 360, Loss: 0.4783\n",
      "Epoch: 361, Loss: 0.4683\n",
      "Epoch: 362, Loss: 0.4761\n",
      "Epoch: 363, Loss: 0.4700\n",
      "Epoch: 364, Loss: 0.4743\n",
      "Epoch: 365, Loss: 0.4733\n",
      "Epoch: 366, Loss: 0.4750\n",
      "Epoch: 367, Loss: 0.4733\n",
      "Epoch: 368, Loss: 0.4708\n",
      "Epoch: 369, Loss: 0.4701\n",
      "Epoch: 370, Loss: 0.4638\n",
      "Epoch: 371, Loss: 0.4691\n",
      "Epoch: 372, Loss: 0.4685\n",
      "Epoch: 373, Loss: 0.4635\n",
      "Epoch: 374, Loss: 0.4681\n",
      "Epoch: 375, Loss: 0.4751\n",
      "Epoch: 376, Loss: 0.4740\n",
      "Epoch: 377, Loss: 0.4726\n",
      "Epoch: 378, Loss: 0.4717\n",
      "Epoch: 379, Loss: 0.4634\n",
      "Epoch: 380, Loss: 0.4634\n",
      "Epoch: 381, Loss: 0.4715\n",
      "Epoch: 382, Loss: 0.4732\n",
      "Epoch: 383, Loss: 0.4709\n",
      "Epoch: 384, Loss: 0.4634\n",
      "Epoch: 385, Loss: 0.4731\n",
      "Epoch: 386, Loss: 0.4712\n",
      "Epoch: 387, Loss: 0.4705\n",
      "Epoch: 388, Loss: 0.4698\n",
      "Epoch: 389, Loss: 0.4744\n",
      "Epoch: 390, Loss: 0.4632\n",
      "Epoch: 391, Loss: 0.4705\n",
      "Epoch: 392, Loss: 0.4631\n",
      "Epoch: 393, Loss: 0.4704\n",
      "Epoch: 394, Loss: 0.4698\n",
      "Epoch: 395, Loss: 0.4691\n",
      "Epoch: 396, Loss: 0.4685\n",
      "Epoch: 397, Loss: 0.4756\n",
      "Epoch: 398, Loss: 0.4692\n",
      "Epoch: 399, Loss: 0.4631\n",
      "Epoch: 400, Loss: 0.4633\n",
      "Epoch: 401, Loss: 0.4707\n",
      "Epoch: 402, Loss: 0.4631\n",
      "Epoch: 403, Loss: 0.4632\n",
      "Epoch: 404, Loss: 0.4632\n",
      "Epoch: 405, Loss: 0.4719\n",
      "Epoch: 406, Loss: 0.4724\n",
      "Epoch: 407, Loss: 0.4715\n",
      "Epoch: 408, Loss: 0.4742\n",
      "Epoch: 409, Loss: 0.4728\n",
      "Epoch: 410, Loss: 0.4718\n",
      "Epoch: 411, Loss: 0.4734\n",
      "Epoch: 412, Loss: 0.4708\n",
      "Epoch: 413, Loss: 0.4699\n",
      "Epoch: 414, Loss: 0.4634\n",
      "Epoch: 415, Loss: 0.4632\n",
      "Epoch: 416, Loss: 0.4631\n",
      "Epoch: 417, Loss: 0.4733\n",
      "Epoch: 418, Loss: 0.4635\n",
      "Epoch: 419, Loss: 0.4635\n",
      "Epoch: 420, Loss: 0.4634\n",
      "Epoch: 421, Loss: 0.4707\n",
      "Epoch: 422, Loss: 0.4635\n",
      "Epoch: 423, Loss: 0.4630\n",
      "Epoch: 424, Loss: 0.4629\n",
      "Epoch: 425, Loss: 0.4737\n",
      "Epoch: 426, Loss: 0.4718\n",
      "Epoch: 427, Loss: 0.4629\n",
      "Epoch: 428, Loss: 0.4723\n",
      "Epoch: 429, Loss: 0.4633\n",
      "Epoch: 430, Loss: 0.4708\n",
      "Epoch: 431, Loss: 0.4698\n",
      "Epoch: 432, Loss: 0.4637\n",
      "Epoch: 433, Loss: 0.4630\n",
      "Epoch: 434, Loss: 0.4628\n",
      "Epoch: 435, Loss: 0.4630\n",
      "Epoch: 436, Loss: 0.4743\n",
      "Epoch: 437, Loss: 0.4641\n",
      "Epoch: 438, Loss: 0.4743\n",
      "Epoch: 439, Loss: 0.4630\n",
      "Epoch: 440, Loss: 0.4629\n",
      "Epoch: 441, Loss: 0.4707\n",
      "Epoch: 442, Loss: 0.4699\n",
      "Epoch: 443, Loss: 0.4630\n",
      "Epoch: 444, Loss: 0.4629\n",
      "Epoch: 445, Loss: 0.4691\n",
      "Epoch: 446, Loss: 0.4750\n",
      "Epoch: 447, Loss: 0.4631\n",
      "Epoch: 448, Loss: 0.4715\n",
      "Epoch: 449, Loss: 0.4728\n",
      "Epoch: 450, Loss: 0.4728\n",
      "Epoch: 451, Loss: 0.4715\n",
      "Epoch: 452, Loss: 0.4633\n",
      "Epoch: 453, Loss: 0.4630\n",
      "Epoch: 454, Loss: 0.4699\n",
      "Epoch: 455, Loss: 0.4740\n",
      "Epoch: 456, Loss: 0.4629\n",
      "Epoch: 457, Loss: 0.4630\n",
      "Epoch: 458, Loss: 0.4721\n",
      "Epoch: 459, Loss: 0.4635\n",
      "Epoch: 460, Loss: 0.4705\n",
      "Epoch: 461, Loss: 0.4745\n",
      "Epoch: 462, Loss: 0.4629\n",
      "Epoch: 463, Loss: 0.4698\n",
      "Epoch: 464, Loss: 0.4692\n",
      "Epoch: 465, Loss: 0.4630\n",
      "Epoch: 466, Loss: 0.4629\n",
      "Epoch: 467, Loss: 0.4734\n",
      "Epoch: 468, Loss: 0.4635\n",
      "Epoch: 469, Loss: 0.4717\n",
      "Epoch: 470, Loss: 0.4707\n",
      "Epoch: 471, Loss: 0.4643\n",
      "Epoch: 472, Loss: 0.4754\n",
      "Epoch: 473, Loss: 0.4629\n",
      "Epoch: 474, Loss: 0.4732\n",
      "Epoch: 475, Loss: 0.4722\n",
      "Epoch: 476, Loss: 0.4712\n",
      "Epoch: 477, Loss: 0.4759\n",
      "Epoch: 478, Loss: 0.4737\n",
      "Epoch: 479, Loss: 0.4693\n",
      "Epoch: 480, Loss: 0.4726\n",
      "Epoch: 481, Loss: 0.4716\n",
      "Epoch: 482, Loss: 0.4639\n",
      "Epoch: 483, Loss: 0.4637\n",
      "Epoch: 484, Loss: 0.4721\n",
      "Epoch: 485, Loss: 0.4711\n",
      "Epoch: 486, Loss: 0.4634\n",
      "Epoch: 487, Loss: 0.4633\n",
      "Epoch: 488, Loss: 0.4632\n",
      "Epoch: 489, Loss: 0.4631\n",
      "Epoch: 490, Loss: 0.4630\n",
      "Epoch: 491, Loss: 0.4704\n",
      "Epoch: 492, Loss: 0.4629\n",
      "Epoch: 493, Loss: 0.4629\n",
      "Epoch: 494, Loss: 0.4700\n",
      "Epoch: 495, Loss: 0.4694\n",
      "Epoch: 496, Loss: 0.4630\n",
      "Epoch: 497, Loss: 0.4743\n",
      "Epoch: 498, Loss: 0.4732\n",
      "Epoch: 499, Loss: 0.4732\n",
      "Epoch: 500, Loss: 0.4713\n",
      "Epoch: 501, Loss: 0.4737\n",
      "Epoch: 502, Loss: 0.4628\n",
      "Epoch: 503, Loss: 0.4701\n",
      "Epoch: 504, Loss: 0.4729\n",
      "Epoch: 505, Loss: 0.4702\n",
      "Epoch: 506, Loss: 0.4721\n",
      "Epoch: 507, Loss: 0.4711\n",
      "Epoch: 508, Loss: 0.4702\n",
      "Epoch: 509, Loss: 0.4693\n",
      "Epoch: 510, Loss: 0.4638\n",
      "Epoch: 511, Loss: 0.4742\n",
      "Epoch: 512, Loss: 0.4632\n",
      "Epoch: 513, Loss: 0.4633\n",
      "Epoch: 514, Loss: 0.4633\n",
      "Epoch: 515, Loss: 0.4634\n",
      "Epoch: 516, Loss: 0.4633\n",
      "Epoch: 517, Loss: 0.4712\n",
      "Epoch: 518, Loss: 0.4629\n",
      "Epoch: 519, Loss: 0.4629\n",
      "Epoch: 520, Loss: 0.4709\n",
      "Epoch: 521, Loss: 0.4628\n",
      "Epoch: 522, Loss: 0.4628\n",
      "Epoch: 523, Loss: 0.4704\n",
      "Epoch: 524, Loss: 0.4731\n",
      "Epoch: 525, Loss: 0.4628\n",
      "Epoch: 526, Loss: 0.4711\n",
      "Epoch: 527, Loss: 0.4723\n",
      "Epoch: 528, Loss: 0.4629\n",
      "Epoch: 529, Loss: 0.4718\n",
      "Epoch: 530, Loss: 0.4715\n",
      "Epoch: 531, Loss: 0.4628\n",
      "Epoch: 532, Loss: 0.4704\n",
      "Epoch: 533, Loss: 0.4731\n",
      "Epoch: 534, Loss: 0.4700\n",
      "Epoch: 535, Loss: 0.4693\n",
      "Epoch: 536, Loss: 0.4629\n",
      "Epoch: 537, Loss: 0.4629\n",
      "Epoch: 538, Loss: 0.4689\n",
      "Epoch: 539, Loss: 0.4684\n",
      "Epoch: 540, Loss: 0.4629\n",
      "Epoch: 541, Loss: 0.4683\n",
      "Epoch: 542, Loss: 0.4736\n",
      "Epoch: 543, Loss: 0.4697\n",
      "Epoch: 544, Loss: 0.4692\n",
      "Epoch: 545, Loss: 0.4629\n",
      "Epoch: 546, Loss: 0.4629\n",
      "Epoch: 547, Loss: 0.4698\n",
      "Epoch: 548, Loss: 0.4692\n",
      "Epoch: 549, Loss: 0.4628\n",
      "Epoch: 550, Loss: 0.4628\n",
      "Epoch: 551, Loss: 0.4629\n",
      "Epoch: 552, Loss: 0.4719\n",
      "Epoch: 553, Loss: 0.4721\n",
      "Epoch: 554, Loss: 0.4708\n",
      "Epoch: 555, Loss: 0.4700\n",
      "Epoch: 556, Loss: 0.4691\n",
      "Epoch: 557, Loss: 0.4633\n",
      "Epoch: 558, Loss: 0.4676\n",
      "Epoch: 559, Loss: 0.4749\n",
      "Epoch: 560, Loss: 0.4734\n",
      "Epoch: 561, Loss: 0.4636\n",
      "Epoch: 562, Loss: 0.4712\n",
      "Epoch: 563, Loss: 0.4704\n",
      "Epoch: 564, Loss: 0.4630\n",
      "Epoch: 565, Loss: 0.4708\n",
      "Epoch: 566, Loss: 0.4633\n",
      "Epoch: 567, Loss: 0.4714\n",
      "Epoch: 568, Loss: 0.4705\n",
      "Epoch: 569, Loss: 0.4631\n",
      "Epoch: 570, Loss: 0.4630\n",
      "Epoch: 571, Loss: 0.4630\n",
      "Epoch: 572, Loss: 0.4697\n",
      "Epoch: 573, Loss: 0.4630\n",
      "Epoch: 574, Loss: 0.4721\n",
      "Epoch: 575, Loss: 0.4712\n",
      "Epoch: 576, Loss: 0.4704\n",
      "Epoch: 577, Loss: 0.4737\n",
      "Epoch: 578, Loss: 0.4629\n",
      "Epoch: 579, Loss: 0.4690\n",
      "Epoch: 580, Loss: 0.4726\n",
      "Epoch: 581, Loss: 0.4694\n",
      "Epoch: 582, Loss: 0.4718\n",
      "Epoch: 583, Loss: 0.4709\n",
      "Epoch: 584, Loss: 0.4718\n",
      "Epoch: 585, Loss: 0.4707\n",
      "Epoch: 586, Loss: 0.4699\n",
      "Epoch: 587, Loss: 0.4692\n",
      "Epoch: 588, Loss: 0.4634\n",
      "Epoch: 589, Loss: 0.4684\n",
      "Epoch: 590, Loss: 0.4678\n",
      "Epoch: 591, Loss: 0.4733\n",
      "Epoch: 592, Loss: 0.4679\n",
      "Epoch: 593, Loss: 0.4722\n",
      "Epoch: 594, Loss: 0.4713\n",
      "Epoch: 595, Loss: 0.4639\n",
      "Epoch: 596, Loss: 0.4637\n",
      "Epoch: 597, Loss: 0.4716\n",
      "Epoch: 598, Loss: 0.4631\n",
      "Epoch: 599, Loss: 0.4693\n",
      "Epoch: 600, Loss: 0.4716\n",
      "Epoch: 601, Loss: 0.4707\n",
      "Epoch: 602, Loss: 0.4632\n",
      "Epoch: 603, Loss: 0.4708\n",
      "Epoch: 604, Loss: 0.4700\n",
      "Epoch: 605, Loss: 0.4693\n",
      "Epoch: 606, Loss: 0.4720\n",
      "Epoch: 607, Loss: 0.4709\n",
      "Epoch: 608, Loss: 0.4702\n",
      "Epoch: 609, Loss: 0.4630\n",
      "Epoch: 610, Loss: 0.4702\n",
      "Epoch: 611, Loss: 0.4695\n",
      "Epoch: 612, Loss: 0.4719\n",
      "Epoch: 613, Loss: 0.4689\n",
      "Epoch: 614, Loss: 0.4684\n",
      "Epoch: 615, Loss: 0.4631\n",
      "Epoch: 616, Loss: 0.4678\n",
      "Epoch: 617, Loss: 0.4673\n",
      "Epoch: 618, Loss: 0.4731\n",
      "Epoch: 619, Loss: 0.4631\n",
      "Epoch: 620, Loss: 0.4687\n",
      "Epoch: 621, Loss: 0.4684\n",
      "Epoch: 622, Loss: 0.4680\n",
      "Epoch: 623, Loss: 0.4629\n",
      "Epoch: 624, Loss: 0.4719\n",
      "Epoch: 625, Loss: 0.4698\n",
      "Epoch: 626, Loss: 0.4692\n",
      "Epoch: 627, Loss: 0.4711\n",
      "Epoch: 628, Loss: 0.4700\n",
      "Epoch: 629, Loss: 0.4629\n",
      "Epoch: 630, Loss: 0.4629\n",
      "Epoch: 631, Loss: 0.4698\n",
      "Epoch: 632, Loss: 0.4629\n",
      "Epoch: 633, Loss: 0.4693\n",
      "Epoch: 634, Loss: 0.4628\n",
      "Epoch: 635, Loss: 0.4713\n",
      "Epoch: 636, Loss: 0.4699\n",
      "Epoch: 637, Loss: 0.4627\n",
      "Epoch: 638, Loss: 0.4627\n",
      "Epoch: 639, Loss: 0.4627\n",
      "Epoch: 640, Loss: 0.4700\n",
      "Epoch: 641, Loss: 0.4693\n",
      "Epoch: 642, Loss: 0.4627\n",
      "Epoch: 643, Loss: 0.4626\n",
      "Epoch: 644, Loss: 0.4626\n",
      "Epoch: 645, Loss: 0.4717\n",
      "Epoch: 646, Loss: 0.4709\n",
      "Epoch: 647, Loss: 0.4626\n",
      "Epoch: 648, Loss: 0.4626\n",
      "Epoch: 649, Loss: 0.4706\n",
      "Epoch: 650, Loss: 0.4628\n",
      "Epoch: 651, Loss: 0.4627\n",
      "Epoch: 652, Loss: 0.4694\n",
      "Epoch: 653, Loss: 0.4627\n",
      "Epoch: 654, Loss: 0.4727\n",
      "Epoch: 655, Loss: 0.4716\n",
      "Epoch: 656, Loss: 0.4707\n",
      "Epoch: 657, Loss: 0.4697\n",
      "Epoch: 658, Loss: 0.4748\n",
      "Epoch: 659, Loss: 0.4629\n",
      "Epoch: 660, Loss: 0.4628\n",
      "Epoch: 661, Loss: 0.4628\n",
      "Epoch: 662, Loss: 0.4629\n",
      "Epoch: 663, Loss: 0.4630\n",
      "Epoch: 664, Loss: 0.4707\n",
      "Epoch: 665, Loss: 0.4715\n",
      "Epoch: 666, Loss: 0.4705\n",
      "Epoch: 667, Loss: 0.4697\n",
      "Epoch: 668, Loss: 0.4629\n",
      "Epoch: 669, Loss: 0.4629\n",
      "Epoch: 670, Loss: 0.4709\n",
      "Epoch: 671, Loss: 0.4629\n",
      "Epoch: 672, Loss: 0.4628\n",
      "Epoch: 673, Loss: 0.4698\n",
      "Epoch: 674, Loss: 0.4629\n",
      "Epoch: 675, Loss: 0.4628\n",
      "Epoch: 676, Loss: 0.4689\n",
      "Epoch: 677, Loss: 0.4683\n",
      "Epoch: 678, Loss: 0.4676\n",
      "Epoch: 679, Loss: 0.4742\n",
      "Epoch: 680, Loss: 0.4727\n",
      "Epoch: 681, Loss: 0.4632\n",
      "Epoch: 682, Loss: 0.4633\n",
      "Epoch: 683, Loss: 0.4710\n",
      "Epoch: 684, Loss: 0.4629\n",
      "Epoch: 685, Loss: 0.4702\n",
      "Epoch: 686, Loss: 0.4695\n",
      "Epoch: 687, Loss: 0.4629\n",
      "Epoch: 688, Loss: 0.4628\n",
      "Epoch: 689, Loss: 0.4628\n",
      "Epoch: 690, Loss: 0.4627\n",
      "Epoch: 691, Loss: 0.4627\n",
      "Epoch: 692, Loss: 0.4627\n",
      "Epoch: 693, Loss: 0.4626\n",
      "Epoch: 694, Loss: 0.4706\n",
      "Epoch: 695, Loss: 0.4719\n",
      "Epoch: 696, Loss: 0.4625\n",
      "Epoch: 697, Loss: 0.4625\n",
      "Epoch: 698, Loss: 0.4703\n",
      "Epoch: 699, Loss: 0.4696\n",
      "Epoch: 700, Loss: 0.4729\n",
      "Epoch: 701, Loss: 0.4716\n",
      "Epoch: 702, Loss: 0.4706\n",
      "Epoch: 703, Loss: 0.4697\n",
      "Epoch: 704, Loss: 0.4710\n",
      "Epoch: 705, Loss: 0.4628\n",
      "Epoch: 706, Loss: 0.4698\n",
      "Epoch: 707, Loss: 0.4691\n",
      "Epoch: 708, Loss: 0.4709\n",
      "Epoch: 709, Loss: 0.4700\n",
      "Epoch: 710, Loss: 0.4632\n",
      "Epoch: 711, Loss: 0.4702\n",
      "Epoch: 712, Loss: 0.4694\n",
      "Epoch: 713, Loss: 0.4701\n",
      "Epoch: 714, Loss: 0.4694\n",
      "Epoch: 715, Loss: 0.4688\n",
      "Epoch: 716, Loss: 0.4633\n",
      "Epoch: 717, Loss: 0.4710\n",
      "Epoch: 718, Loss: 0.4701\n",
      "Epoch: 719, Loss: 0.4696\n",
      "Epoch: 720, Loss: 0.4630\n",
      "Epoch: 721, Loss: 0.4696\n",
      "Epoch: 722, Loss: 0.4702\n",
      "Epoch: 723, Loss: 0.4693\n",
      "Epoch: 724, Loss: 0.4630\n",
      "Epoch: 725, Loss: 0.4629\n",
      "Epoch: 726, Loss: 0.4687\n",
      "Epoch: 727, Loss: 0.4628\n",
      "Epoch: 728, Loss: 0.4711\n",
      "Epoch: 729, Loss: 0.4628\n",
      "Epoch: 730, Loss: 0.4697\n",
      "Epoch: 731, Loss: 0.4691\n",
      "Epoch: 732, Loss: 0.4685\n",
      "Epoch: 733, Loss: 0.4679\n",
      "Epoch: 734, Loss: 0.4628\n",
      "Epoch: 735, Loss: 0.4673\n",
      "Epoch: 736, Loss: 0.4728\n",
      "Epoch: 737, Loss: 0.4716\n",
      "Epoch: 738, Loss: 0.4708\n",
      "Epoch: 739, Loss: 0.4699\n",
      "Epoch: 740, Loss: 0.4736\n",
      "Epoch: 741, Loss: 0.4716\n",
      "Epoch: 742, Loss: 0.4630\n",
      "Epoch: 743, Loss: 0.4680\n",
      "Epoch: 744, Loss: 0.4705\n",
      "Epoch: 745, Loss: 0.4633\n",
      "Epoch: 746, Loss: 0.4688\n",
      "Epoch: 747, Loss: 0.4697\n",
      "Epoch: 748, Loss: 0.4694\n",
      "Epoch: 749, Loss: 0.4688\n",
      "Epoch: 750, Loss: 0.4630\n",
      "Epoch: 751, Loss: 0.4629\n",
      "Epoch: 752, Loss: 0.4629\n",
      "Epoch: 753, Loss: 0.4628\n",
      "Epoch: 754, Loss: 0.4692\n",
      "Epoch: 755, Loss: 0.4707\n",
      "Epoch: 756, Loss: 0.4627\n",
      "Epoch: 757, Loss: 0.4700\n",
      "Epoch: 758, Loss: 0.4693\n",
      "Epoch: 759, Loss: 0.4713\n",
      "Epoch: 760, Loss: 0.4703\n",
      "Epoch: 761, Loss: 0.4629\n",
      "Epoch: 762, Loss: 0.4705\n",
      "Epoch: 763, Loss: 0.4696\n",
      "Epoch: 764, Loss: 0.4628\n",
      "Epoch: 765, Loss: 0.4628\n",
      "Epoch: 766, Loss: 0.4627\n",
      "Epoch: 767, Loss: 0.4702\n",
      "Epoch: 768, Loss: 0.4698\n",
      "Epoch: 769, Loss: 0.4691\n",
      "Epoch: 770, Loss: 0.4685\n",
      "Epoch: 771, Loss: 0.4715\n",
      "Epoch: 772, Loss: 0.4628\n",
      "Epoch: 773, Loss: 0.4701\n",
      "Epoch: 774, Loss: 0.4694\n",
      "Epoch: 775, Loss: 0.4687\n",
      "Epoch: 776, Loss: 0.4634\n",
      "Epoch: 777, Loss: 0.4674\n",
      "Epoch: 778, Loss: 0.4668\n",
      "Epoch: 779, Loss: 0.4731\n",
      "Epoch: 780, Loss: 0.4716\n",
      "Epoch: 781, Loss: 0.4707\n",
      "Epoch: 782, Loss: 0.4638\n",
      "Epoch: 783, Loss: 0.4637\n",
      "Epoch: 784, Loss: 0.4688\n",
      "Epoch: 785, Loss: 0.4638\n",
      "Epoch: 786, Loss: 0.4715\n",
      "Epoch: 787, Loss: 0.4676\n",
      "Epoch: 788, Loss: 0.4672\n",
      "Epoch: 789, Loss: 0.4668\n",
      "Epoch: 790, Loss: 0.4630\n",
      "Epoch: 791, Loss: 0.4666\n",
      "Epoch: 792, Loss: 0.4719\n",
      "Epoch: 793, Loss: 0.4678\n",
      "Epoch: 794, Loss: 0.4709\n",
      "Epoch: 795, Loss: 0.4693\n",
      "Epoch: 796, Loss: 0.4698\n",
      "Epoch: 797, Loss: 0.4634\n",
      "Epoch: 798, Loss: 0.4632\n",
      "Epoch: 799, Loss: 0.4631\n",
      "Epoch: 800, Loss: 0.4629\n",
      "Epoch: 801, Loss: 0.4704\n",
      "Epoch: 802, Loss: 0.4627\n",
      "Epoch: 803, Loss: 0.4695\n",
      "Epoch: 804, Loss: 0.4704\n",
      "Epoch: 805, Loss: 0.4691\n",
      "Epoch: 806, Loss: 0.4705\n",
      "Epoch: 807, Loss: 0.4627\n",
      "Epoch: 808, Loss: 0.4690\n",
      "Epoch: 809, Loss: 0.4627\n",
      "Epoch: 810, Loss: 0.4627\n",
      "Epoch: 811, Loss: 0.4700\n",
      "Epoch: 812, Loss: 0.4696\n",
      "Epoch: 813, Loss: 0.4627\n",
      "Epoch: 814, Loss: 0.4627\n",
      "Epoch: 815, Loss: 0.4692\n",
      "Epoch: 816, Loss: 0.4686\n",
      "Epoch: 817, Loss: 0.4680\n",
      "Epoch: 818, Loss: 0.4630\n",
      "Epoch: 819, Loss: 0.4717\n",
      "Epoch: 820, Loss: 0.4707\n",
      "Epoch: 821, Loss: 0.4699\n",
      "Epoch: 822, Loss: 0.4714\n",
      "Epoch: 823, Loss: 0.4701\n",
      "Epoch: 824, Loss: 0.4692\n",
      "Epoch: 825, Loss: 0.4630\n",
      "Epoch: 826, Loss: 0.4684\n",
      "Epoch: 827, Loss: 0.4632\n",
      "Epoch: 828, Loss: 0.4700\n",
      "Epoch: 829, Loss: 0.4692\n",
      "Epoch: 830, Loss: 0.4631\n",
      "Epoch: 831, Loss: 0.4629\n",
      "Epoch: 832, Loss: 0.4696\n",
      "Epoch: 833, Loss: 0.4690\n",
      "Epoch: 834, Loss: 0.4697\n",
      "Epoch: 835, Loss: 0.4628\n",
      "Epoch: 836, Loss: 0.4627\n",
      "Epoch: 837, Loss: 0.4690\n",
      "Epoch: 838, Loss: 0.4628\n",
      "Epoch: 839, Loss: 0.4626\n",
      "Epoch: 840, Loss: 0.4704\n",
      "Epoch: 841, Loss: 0.4626\n",
      "Epoch: 842, Loss: 0.4696\n",
      "Epoch: 843, Loss: 0.4625\n",
      "Epoch: 844, Loss: 0.4625\n",
      "Epoch: 845, Loss: 0.4700\n",
      "Epoch: 846, Loss: 0.4703\n",
      "Epoch: 847, Loss: 0.4696\n",
      "Epoch: 848, Loss: 0.4626\n",
      "Epoch: 849, Loss: 0.4687\n",
      "Epoch: 850, Loss: 0.4681\n",
      "Epoch: 851, Loss: 0.4720\n",
      "Epoch: 852, Loss: 0.4626\n",
      "Epoch: 853, Loss: 0.4703\n",
      "Epoch: 854, Loss: 0.4630\n",
      "Epoch: 855, Loss: 0.4695\n",
      "Epoch: 856, Loss: 0.4628\n",
      "Epoch: 857, Loss: 0.4689\n",
      "Epoch: 858, Loss: 0.4695\n",
      "Epoch: 859, Loss: 0.4690\n",
      "Epoch: 860, Loss: 0.4628\n",
      "Epoch: 861, Loss: 0.4628\n",
      "Epoch: 862, Loss: 0.4686\n",
      "Epoch: 863, Loss: 0.4700\n",
      "Epoch: 864, Loss: 0.4692\n",
      "Epoch: 865, Loss: 0.4629\n",
      "Epoch: 866, Loss: 0.4699\n",
      "Epoch: 867, Loss: 0.4688\n",
      "Epoch: 868, Loss: 0.4628\n",
      "Epoch: 869, Loss: 0.4627\n",
      "Epoch: 870, Loss: 0.4683\n",
      "Epoch: 871, Loss: 0.4627\n",
      "Epoch: 872, Loss: 0.4626\n",
      "Epoch: 873, Loss: 0.4626\n",
      "Epoch: 874, Loss: 0.4702\n",
      "Epoch: 875, Loss: 0.4627\n",
      "Epoch: 876, Loss: 0.4701\n",
      "Epoch: 877, Loss: 0.4625\n",
      "Epoch: 878, Loss: 0.4625\n",
      "Epoch: 879, Loss: 0.4696\n",
      "Epoch: 880, Loss: 0.4704\n",
      "Epoch: 881, Loss: 0.4696\n",
      "Epoch: 882, Loss: 0.4627\n",
      "Epoch: 883, Loss: 0.4626\n",
      "Epoch: 884, Loss: 0.4626\n",
      "Epoch: 885, Loss: 0.4685\n",
      "Epoch: 886, Loss: 0.4679\n",
      "Epoch: 887, Loss: 0.4674\n",
      "Epoch: 888, Loss: 0.4726\n",
      "Epoch: 889, Loss: 0.4673\n",
      "Epoch: 890, Loss: 0.4712\n",
      "Epoch: 891, Loss: 0.4702\n",
      "Epoch: 892, Loss: 0.4699\n",
      "Epoch: 893, Loss: 0.4688\n",
      "Epoch: 894, Loss: 0.4701\n",
      "Epoch: 895, Loss: 0.4631\n",
      "Epoch: 896, Loss: 0.4631\n",
      "Epoch: 897, Loss: 0.4691\n",
      "Epoch: 898, Loss: 0.4685\n",
      "Epoch: 899, Loss: 0.4681\n",
      "Epoch: 900, Loss: 0.4676\n",
      "Epoch: 901, Loss: 0.4672\n",
      "Epoch: 902, Loss: 0.4630\n",
      "Epoch: 903, Loss: 0.4709\n",
      "Epoch: 904, Loss: 0.4628\n",
      "Epoch: 905, Loss: 0.4698\n",
      "Epoch: 906, Loss: 0.4631\n",
      "Epoch: 907, Loss: 0.4688\n",
      "Epoch: 908, Loss: 0.4713\n",
      "Epoch: 909, Loss: 0.4701\n",
      "Epoch: 910, Loss: 0.4692\n",
      "Epoch: 911, Loss: 0.4693\n",
      "Epoch: 912, Loss: 0.4628\n",
      "Epoch: 913, Loss: 0.4686\n",
      "Epoch: 914, Loss: 0.4629\n",
      "Epoch: 915, Loss: 0.4692\n",
      "Epoch: 916, Loss: 0.4628\n",
      "Epoch: 917, Loss: 0.4628\n",
      "Epoch: 918, Loss: 0.4627\n",
      "Epoch: 919, Loss: 0.4626\n",
      "Epoch: 920, Loss: 0.4695\n",
      "Epoch: 921, Loss: 0.4689\n",
      "Epoch: 922, Loss: 0.4627\n",
      "Epoch: 923, Loss: 0.4681\n",
      "Epoch: 924, Loss: 0.4626\n",
      "Epoch: 925, Loss: 0.4715\n",
      "Epoch: 926, Loss: 0.4626\n",
      "Epoch: 927, Loss: 0.4688\n",
      "Epoch: 928, Loss: 0.4625\n",
      "Epoch: 929, Loss: 0.4685\n",
      "Epoch: 930, Loss: 0.4625\n",
      "Epoch: 931, Loss: 0.4681\n",
      "Epoch: 932, Loss: 0.4625\n",
      "Epoch: 933, Loss: 0.4679\n",
      "Epoch: 934, Loss: 0.4710\n",
      "Epoch: 935, Loss: 0.4700\n",
      "Epoch: 936, Loss: 0.4698\n",
      "Epoch: 937, Loss: 0.4689\n",
      "Epoch: 938, Loss: 0.4682\n",
      "Epoch: 939, Loss: 0.4632\n",
      "Epoch: 940, Loss: 0.4631\n",
      "Epoch: 941, Loss: 0.4703\n",
      "Epoch: 942, Loss: 0.4694\n",
      "Epoch: 943, Loss: 0.4687\n",
      "Epoch: 944, Loss: 0.4681\n",
      "Epoch: 945, Loss: 0.4691\n",
      "Epoch: 946, Loss: 0.4630\n",
      "Epoch: 947, Loss: 0.4630\n",
      "Epoch: 948, Loss: 0.4629\n",
      "Epoch: 949, Loss: 0.4628\n",
      "Epoch: 950, Loss: 0.4691\n",
      "Epoch: 951, Loss: 0.4686\n",
      "Epoch: 952, Loss: 0.4627\n",
      "Epoch: 953, Loss: 0.4626\n",
      "Epoch: 954, Loss: 0.4702\n",
      "Epoch: 955, Loss: 0.4625\n",
      "Epoch: 956, Loss: 0.4625\n",
      "Epoch: 957, Loss: 0.4693\n",
      "Epoch: 958, Loss: 0.4627\n",
      "Epoch: 959, Loss: 0.4684\n",
      "Epoch: 960, Loss: 0.4678\n",
      "Epoch: 961, Loss: 0.4627\n",
      "Epoch: 962, Loss: 0.4626\n",
      "Epoch: 963, Loss: 0.4624\n",
      "Epoch: 964, Loss: 0.4625\n",
      "Epoch: 965, Loss: 0.4711\n",
      "Epoch: 966, Loss: 0.4704\n",
      "Epoch: 967, Loss: 0.4636\n",
      "Epoch: 968, Loss: 0.4631\n",
      "Epoch: 969, Loss: 0.4628\n",
      "Epoch: 970, Loss: 0.4712\n",
      "Epoch: 971, Loss: 0.4701\n",
      "Epoch: 972, Loss: 0.4628\n",
      "Epoch: 973, Loss: 0.4693\n",
      "Epoch: 974, Loss: 0.4686\n",
      "Epoch: 975, Loss: 0.4693\n",
      "Epoch: 976, Loss: 0.4628\n",
      "Epoch: 977, Loss: 0.4684\n",
      "Epoch: 978, Loss: 0.4696\n",
      "Epoch: 979, Loss: 0.4681\n",
      "Epoch: 980, Loss: 0.4629\n",
      "Epoch: 981, Loss: 0.4629\n",
      "Epoch: 982, Loss: 0.4677\n",
      "Epoch: 983, Loss: 0.4700\n",
      "Epoch: 984, Loss: 0.4680\n",
      "Epoch: 985, Loss: 0.4696\n",
      "Epoch: 986, Loss: 0.4628\n",
      "Epoch: 987, Loss: 0.4686\n",
      "Epoch: 988, Loss: 0.4627\n",
      "Epoch: 989, Loss: 0.4627\n",
      "Epoch: 990, Loss: 0.4626\n",
      "Epoch: 991, Loss: 0.4690\n",
      "Epoch: 992, Loss: 0.4698\n",
      "Epoch: 993, Loss: 0.4690\n",
      "Epoch: 994, Loss: 0.4695\n",
      "Epoch: 995, Loss: 0.4688\n",
      "Epoch: 996, Loss: 0.4627\n",
      "Epoch: 997, Loss: 0.4681\n",
      "Epoch: 998, Loss: 0.4628\n",
      "Epoch: 999, Loss: 0.4627\n",
      "Epoch: 1000, Loss: 0.4698\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "epochs = 1000\n",
    "batch_size = 3\n",
    "cbow = CBOW(len(word_to_id), 3).to(device)\n",
    "optimizer = torch.optim.Adam(cbow.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "hist_loss = []\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(contexts, target)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = cbow(x)\n",
    "        loss = loss_fn(out, torch.max(y, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    hist_loss.append(total_loss)\n",
    "    print('Epoch: {}, Loss: {:.4f}'.format(epoch+1, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 3, 4, 1, 5])\n",
      "tensor([1, 2, 3, 4, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "cbow.eval()\n",
    "\n",
    "h = cbow(contexts)\n",
    "h = nn.Softmax(dim=1)(h)\n",
    "ids = torch.argmax(h, dim=1)\n",
    "print(ids)\n",
    "target_ids = torch.argmax(target, dim=1)\n",
    "print(target_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec：Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skip_gram(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, window_size=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.in_layer = nn.Linear(vocab_size, hidden_size, bias=False)\n",
    "        self.out_layers = nn.ModuleList([nn.Linear(hidden_size, vocab_size, bias=False) for _ in range(window_size*2)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.in_layer(x)\n",
    "        outs = torch.zeros(self.window_size*2, x.size(0), self.vocab_size).to(device)\n",
    "\n",
    "        for i in range(self.window_size*2):\n",
    "            outs[i] = self.out_layers[i](h)\n",
    "        \n",
    "        outs = outs.permute(1, 0, 2)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utills import preprocess, create_co_matrix\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "contexts = []\n",
    "target = []\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "contexts = convert_one_hot(contexts, len(word_to_id))\n",
    "target = convert_one_hot(target, len(word_to_id))\n",
    "\n",
    "contexts = torch.tensor(contexts, dtype=torch.float32).to(device)\n",
    "target = torch.tensor(target, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.2925e-03,  1.5181e-01, -6.9794e-03,  1.4278e-01,  2.4935e-02,\n",
       "           8.5825e-02,  2.9294e-02],\n",
       "         [ 1.1800e-01,  9.6726e-02,  1.4390e-01,  2.5298e-01, -2.1166e-01,\n",
       "          -8.4658e-02,  4.0979e-02]],\n",
       "\n",
       "        [[-2.8242e-01,  8.4313e-02,  3.1755e-01,  6.6480e-02,  1.9356e-02,\n",
       "          -2.0018e-01, -3.0315e-01],\n",
       "         [-1.2399e-01,  2.4902e-01,  2.3009e-01,  2.1007e-01, -1.9345e-01,\n",
       "           7.4020e-03,  1.5996e-01]],\n",
       "\n",
       "        [[ 8.6090e-03,  7.7049e-04, -6.8649e-02,  6.8159e-02,  8.3572e-02,\n",
       "           6.2565e-02,  1.1617e-02],\n",
       "         [-5.3538e-02, -8.4568e-02, -6.4010e-02,  1.1171e-02, -2.5755e-02,\n",
       "          -1.5471e-02, -1.2162e-01]],\n",
       "\n",
       "        [[-1.4617e-04, -2.4230e-02, -7.8610e-02,  6.9059e-02,  1.1063e-01,\n",
       "           6.0415e-02, -3.1801e-03],\n",
       "         [-1.0147e-01, -1.2332e-01, -1.0501e-01, -2.3731e-02, -3.4211e-03,\n",
       "          -4.6793e-03, -1.6739e-01]],\n",
       "\n",
       "        [[-3.2925e-03,  1.5181e-01, -6.9794e-03,  1.4278e-01,  2.4935e-02,\n",
       "           8.5825e-02,  2.9294e-02],\n",
       "         [ 1.1800e-01,  9.6726e-02,  1.4390e-01,  2.5298e-01, -2.1166e-01,\n",
       "          -8.4658e-02,  4.0979e-02]],\n",
       "\n",
       "        [[-7.9099e-02,  4.6056e-02,  1.4909e-01, -3.0725e-02, -7.8801e-02,\n",
       "          -1.0025e-01, -8.1753e-02],\n",
       "         [ 4.6082e-02,  1.6681e-01,  1.4866e-01,  8.3472e-02, -5.6941e-02,\n",
       "           3.5172e-03,  1.7425e-01]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skg = Skip_gram(len(word_to_id), 3).to(device)\n",
    "h = skg(target)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1338, 0.1562, 0.1333, 0.1548, 0.1376, 0.1462, 0.1382],\n",
       "         [0.1513, 0.1481, 0.1552, 0.1731, 0.1088, 0.1235, 0.1400]],\n",
       "\n",
       "        [[0.1099, 0.1586, 0.2002, 0.1558, 0.1486, 0.1193, 0.1076],\n",
       "         [0.1153, 0.1674, 0.1642, 0.1610, 0.1075, 0.1315, 0.1531]],\n",
       "\n",
       "        [[0.1405, 0.1394, 0.1301, 0.1492, 0.1515, 0.1483, 0.1410],\n",
       "         [0.1423, 0.1380, 0.1408, 0.1518, 0.1463, 0.1478, 0.1329]],\n",
       "\n",
       "        [[0.1399, 0.1366, 0.1293, 0.1499, 0.1563, 0.1486, 0.1395],\n",
       "         [0.1390, 0.1360, 0.1385, 0.1502, 0.1533, 0.1531, 0.1301]],\n",
       "\n",
       "        [[0.1338, 0.1562, 0.1333, 0.1548, 0.1376, 0.1462, 0.1382],\n",
       "         [0.1513, 0.1481, 0.1552, 0.1731, 0.1088, 0.1235, 0.1400]],\n",
       "\n",
       "        [[0.1348, 0.1528, 0.1694, 0.1415, 0.1349, 0.1320, 0.1345],\n",
       "         [0.1375, 0.1552, 0.1524, 0.1428, 0.1241, 0.1318, 0.1563]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = nn.Softmax(dim=2)(h)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9374, -1.9709], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.log(h[0]) * contexts[0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8034, -2.0998],\n",
       "        [-1.8444, -1.9928],\n",
       "        [-2.2531, -1.8134],\n",
       "        [-2.0392, -1.7114],\n",
       "        [-2.0461, -1.8309],\n",
       "        [-1.7763, -1.8358]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.log(h) * contexts, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(out, contexts):\n",
    "    out = nn.Softmax(dim=2)(out)\n",
    "    loss = torch.sum(torch.log(out) * contexts, dim=2)\n",
    "    loss = torch.sum(loss, dim=1)\n",
    "    loss = -torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "contexts = []\n",
    "target = []\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "contexts = convert_one_hot(contexts, len(word_to_id))\n",
    "target = convert_one_hot(target, len(word_to_id))\n",
    "\n",
    "contexts = torch.tensor(contexts, dtype=torch.float32).to(device)\n",
    "target = torch.tensor(target, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 7.6316\n",
      "Epoch: 2, Loss: 7.5733\n",
      "Epoch: 3, Loss: 7.5136\n",
      "Epoch: 4, Loss: 7.4577\n",
      "Epoch: 5, Loss: 7.3996\n",
      "Epoch: 6, Loss: 7.3334\n",
      "Epoch: 7, Loss: 7.2664\n",
      "Epoch: 8, Loss: 7.1997\n",
      "Epoch: 9, Loss: 7.1233\n",
      "Epoch: 10, Loss: 7.0482\n",
      "Epoch: 11, Loss: 6.9684\n",
      "Epoch: 12, Loss: 6.8823\n",
      "Epoch: 13, Loss: 6.7925\n",
      "Epoch: 14, Loss: 6.6986\n",
      "Epoch: 15, Loss: 6.5969\n",
      "Epoch: 16, Loss: 6.4965\n",
      "Epoch: 17, Loss: 6.3911\n",
      "Epoch: 18, Loss: 6.2766\n",
      "Epoch: 19, Loss: 6.1650\n",
      "Epoch: 20, Loss: 6.0428\n",
      "Epoch: 21, Loss: 5.9202\n",
      "Epoch: 22, Loss: 5.7929\n",
      "Epoch: 23, Loss: 5.6680\n",
      "Epoch: 24, Loss: 5.5396\n",
      "Epoch: 25, Loss: 5.4061\n",
      "Epoch: 26, Loss: 5.2706\n",
      "Epoch: 27, Loss: 5.1345\n",
      "Epoch: 28, Loss: 4.9978\n",
      "Epoch: 29, Loss: 4.8578\n",
      "Epoch: 30, Loss: 4.7174\n",
      "Epoch: 31, Loss: 4.5791\n",
      "Epoch: 32, Loss: 4.4437\n",
      "Epoch: 33, Loss: 4.3043\n",
      "Epoch: 34, Loss: 4.1749\n",
      "Epoch: 35, Loss: 4.0377\n",
      "Epoch: 36, Loss: 3.9086\n",
      "Epoch: 37, Loss: 3.7751\n",
      "Epoch: 38, Loss: 3.6486\n",
      "Epoch: 39, Loss: 3.5248\n",
      "Epoch: 40, Loss: 3.4049\n",
      "Epoch: 41, Loss: 3.2866\n",
      "Epoch: 42, Loss: 3.1779\n",
      "Epoch: 43, Loss: 3.0619\n",
      "Epoch: 44, Loss: 2.9606\n",
      "Epoch: 45, Loss: 2.8502\n",
      "Epoch: 46, Loss: 2.7523\n",
      "Epoch: 47, Loss: 2.6541\n",
      "Epoch: 48, Loss: 2.5659\n",
      "Epoch: 49, Loss: 2.4912\n",
      "Epoch: 50, Loss: 2.4057\n",
      "Epoch: 51, Loss: 2.3304\n",
      "Epoch: 52, Loss: 2.2576\n",
      "Epoch: 53, Loss: 2.1868\n",
      "Epoch: 54, Loss: 2.1129\n",
      "Epoch: 55, Loss: 2.0481\n",
      "Epoch: 56, Loss: 1.9951\n",
      "Epoch: 57, Loss: 1.9394\n",
      "Epoch: 58, Loss: 1.8907\n",
      "Epoch: 59, Loss: 1.8454\n",
      "Epoch: 60, Loss: 1.7987\n",
      "Epoch: 61, Loss: 1.7503\n",
      "Epoch: 62, Loss: 1.7129\n",
      "Epoch: 63, Loss: 1.6771\n",
      "Epoch: 64, Loss: 1.6414\n",
      "Epoch: 65, Loss: 1.6050\n",
      "Epoch: 66, Loss: 1.5768\n",
      "Epoch: 67, Loss: 1.5474\n",
      "Epoch: 68, Loss: 1.5216\n",
      "Epoch: 69, Loss: 1.4927\n",
      "Epoch: 70, Loss: 1.4706\n",
      "Epoch: 71, Loss: 1.4485\n",
      "Epoch: 72, Loss: 1.4241\n",
      "Epoch: 73, Loss: 1.4067\n",
      "Epoch: 74, Loss: 1.3859\n",
      "Epoch: 75, Loss: 1.3681\n",
      "Epoch: 76, Loss: 1.3564\n",
      "Epoch: 77, Loss: 1.3361\n",
      "Epoch: 78, Loss: 1.3211\n",
      "Epoch: 79, Loss: 1.3132\n",
      "Epoch: 80, Loss: 1.2939\n",
      "Epoch: 81, Loss: 1.2814\n",
      "Epoch: 82, Loss: 1.2744\n",
      "Epoch: 83, Loss: 1.2632\n",
      "Epoch: 84, Loss: 1.2524\n",
      "Epoch: 85, Loss: 1.2430\n",
      "Epoch: 86, Loss: 1.2319\n",
      "Epoch: 87, Loss: 1.2240\n",
      "Epoch: 88, Loss: 1.2103\n",
      "Epoch: 89, Loss: 1.2063\n",
      "Epoch: 90, Loss: 1.1935\n",
      "Epoch: 91, Loss: 1.1860\n",
      "Epoch: 92, Loss: 1.1831\n",
      "Epoch: 93, Loss: 1.1757\n",
      "Epoch: 94, Loss: 1.1706\n",
      "Epoch: 95, Loss: 1.1627\n",
      "Epoch: 96, Loss: 1.1526\n",
      "Epoch: 97, Loss: 1.1469\n",
      "Epoch: 98, Loss: 1.1451\n",
      "Epoch: 99, Loss: 1.1411\n",
      "Epoch: 100, Loss: 1.1306\n",
      "Epoch: 101, Loss: 1.1254\n",
      "Epoch: 102, Loss: 1.1254\n",
      "Epoch: 103, Loss: 1.1162\n",
      "Epoch: 104, Loss: 1.1159\n",
      "Epoch: 105, Loss: 1.1129\n",
      "Epoch: 106, Loss: 1.1033\n",
      "Epoch: 107, Loss: 1.0993\n",
      "Epoch: 108, Loss: 1.0953\n",
      "Epoch: 109, Loss: 1.0917\n",
      "Epoch: 110, Loss: 1.0882\n",
      "Epoch: 111, Loss: 1.0846\n",
      "Epoch: 112, Loss: 1.0864\n",
      "Epoch: 113, Loss: 1.0781\n",
      "Epoch: 114, Loss: 1.0796\n",
      "Epoch: 115, Loss: 1.0760\n",
      "Epoch: 116, Loss: 1.0727\n",
      "Epoch: 117, Loss: 1.0662\n",
      "Epoch: 118, Loss: 1.0697\n",
      "Epoch: 119, Loss: 1.0648\n",
      "Epoch: 120, Loss: 1.0640\n",
      "Epoch: 121, Loss: 1.0555\n",
      "Epoch: 122, Loss: 1.0583\n",
      "Epoch: 123, Loss: 1.0559\n",
      "Epoch: 124, Loss: 1.0535\n",
      "Epoch: 125, Loss: 1.0508\n",
      "Epoch: 126, Loss: 1.0443\n",
      "Epoch: 127, Loss: 1.0421\n",
      "Epoch: 128, Loss: 1.0457\n",
      "Epoch: 129, Loss: 1.0426\n",
      "Epoch: 130, Loss: 1.0416\n",
      "Epoch: 131, Loss: 1.0342\n",
      "Epoch: 132, Loss: 1.0323\n",
      "Epoch: 133, Loss: 1.0305\n",
      "Epoch: 134, Loss: 1.0338\n",
      "Epoch: 135, Loss: 1.0272\n",
      "Epoch: 136, Loss: 1.0309\n",
      "Epoch: 137, Loss: 1.0287\n",
      "Epoch: 138, Loss: 1.0223\n",
      "Epoch: 139, Loss: 1.0208\n",
      "Epoch: 140, Loss: 1.0247\n",
      "Epoch: 141, Loss: 1.0178\n",
      "Epoch: 142, Loss: 1.0213\n",
      "Epoch: 143, Loss: 1.0150\n",
      "Epoch: 144, Loss: 1.0137\n",
      "Epoch: 145, Loss: 1.0123\n",
      "Epoch: 146, Loss: 1.0110\n",
      "Epoch: 147, Loss: 1.0097\n",
      "Epoch: 148, Loss: 1.0085\n",
      "Epoch: 149, Loss: 1.0122\n",
      "Epoch: 150, Loss: 1.0106\n",
      "Epoch: 151, Loss: 1.0090\n",
      "Epoch: 152, Loss: 1.0040\n",
      "Epoch: 153, Loss: 1.0066\n",
      "Epoch: 154, Loss: 1.0018\n",
      "Epoch: 155, Loss: 1.0043\n",
      "Epoch: 156, Loss: 1.0065\n",
      "Epoch: 157, Loss: 1.0047\n",
      "Epoch: 158, Loss: 1.0025\n",
      "Epoch: 159, Loss: 0.9966\n",
      "Epoch: 160, Loss: 1.0004\n",
      "Epoch: 161, Loss: 0.9948\n",
      "Epoch: 162, Loss: 0.9996\n",
      "Epoch: 163, Loss: 0.9981\n",
      "Epoch: 164, Loss: 0.9923\n",
      "Epoch: 165, Loss: 0.9972\n",
      "Epoch: 166, Loss: 0.9904\n",
      "Epoch: 167, Loss: 0.9945\n",
      "Epoch: 168, Loss: 0.9947\n",
      "Epoch: 169, Loss: 0.9880\n",
      "Epoch: 170, Loss: 0.9922\n",
      "Epoch: 171, Loss: 0.9923\n",
      "Epoch: 172, Loss: 0.9857\n",
      "Epoch: 173, Loss: 0.9900\n",
      "Epoch: 174, Loss: 0.9900\n",
      "Epoch: 175, Loss: 0.9886\n",
      "Epoch: 176, Loss: 0.9884\n",
      "Epoch: 177, Loss: 0.9822\n",
      "Epoch: 178, Loss: 0.9815\n",
      "Epoch: 179, Loss: 0.9859\n",
      "Epoch: 180, Loss: 0.9860\n",
      "Epoch: 181, Loss: 0.9847\n",
      "Epoch: 182, Loss: 0.9845\n",
      "Epoch: 183, Loss: 0.9835\n",
      "Epoch: 184, Loss: 0.9778\n",
      "Epoch: 185, Loss: 0.9819\n",
      "Epoch: 186, Loss: 0.9767\n",
      "Epoch: 187, Loss: 0.9819\n",
      "Epoch: 188, Loss: 0.9755\n",
      "Epoch: 189, Loss: 0.9801\n",
      "Epoch: 190, Loss: 0.9799\n",
      "Epoch: 191, Loss: 0.9790\n",
      "Epoch: 192, Loss: 0.9789\n",
      "Epoch: 193, Loss: 0.9779\n",
      "Epoch: 194, Loss: 0.9778\n",
      "Epoch: 195, Loss: 0.9769\n",
      "Epoch: 196, Loss: 0.9714\n",
      "Epoch: 197, Loss: 0.9709\n",
      "Epoch: 198, Loss: 0.9704\n",
      "Epoch: 199, Loss: 0.9753\n",
      "Epoch: 200, Loss: 0.9743\n",
      "Epoch: 201, Loss: 0.9691\n",
      "Epoch: 202, Loss: 0.9730\n",
      "Epoch: 203, Loss: 0.9744\n",
      "Epoch: 204, Loss: 0.9733\n",
      "Epoch: 205, Loss: 0.9673\n",
      "Epoch: 206, Loss: 0.9719\n",
      "Epoch: 207, Loss: 0.9665\n",
      "Epoch: 208, Loss: 0.9717\n",
      "Epoch: 209, Loss: 0.9707\n",
      "Epoch: 210, Loss: 0.9709\n",
      "Epoch: 211, Loss: 0.9699\n",
      "Epoch: 212, Loss: 0.9645\n",
      "Epoch: 213, Loss: 0.9642\n",
      "Epoch: 214, Loss: 0.9693\n",
      "Epoch: 215, Loss: 0.9684\n",
      "Epoch: 216, Loss: 0.9631\n",
      "Epoch: 217, Loss: 0.9683\n",
      "Epoch: 218, Loss: 0.9623\n",
      "Epoch: 219, Loss: 0.9620\n",
      "Epoch: 220, Loss: 0.9616\n",
      "Epoch: 221, Loss: 0.9664\n",
      "Epoch: 222, Loss: 0.9666\n",
      "Epoch: 223, Loss: 0.9607\n",
      "Epoch: 224, Loss: 0.9603\n",
      "Epoch: 225, Loss: 0.9600\n",
      "Epoch: 226, Loss: 0.9649\n",
      "Epoch: 227, Loss: 0.9651\n",
      "Epoch: 228, Loss: 0.9643\n",
      "Epoch: 229, Loss: 0.9588\n",
      "Epoch: 230, Loss: 0.9633\n",
      "Epoch: 231, Loss: 0.9625\n",
      "Epoch: 232, Loss: 0.9644\n",
      "Epoch: 233, Loss: 0.9634\n",
      "Epoch: 234, Loss: 0.9574\n",
      "Epoch: 235, Loss: 0.9571\n",
      "Epoch: 236, Loss: 0.9619\n",
      "Epoch: 237, Loss: 0.9566\n",
      "Epoch: 238, Loss: 0.9563\n",
      "Epoch: 239, Loss: 0.9618\n",
      "Epoch: 240, Loss: 0.9609\n",
      "Epoch: 241, Loss: 0.9555\n",
      "Epoch: 242, Loss: 0.9552\n",
      "Epoch: 243, Loss: 0.9606\n",
      "Epoch: 244, Loss: 0.9548\n",
      "Epoch: 245, Loss: 0.9596\n",
      "Epoch: 246, Loss: 0.9543\n",
      "Epoch: 247, Loss: 0.9586\n",
      "Epoch: 248, Loss: 0.9602\n",
      "Epoch: 249, Loss: 0.9592\n",
      "Epoch: 250, Loss: 0.9533\n",
      "Epoch: 251, Loss: 0.9584\n",
      "Epoch: 252, Loss: 0.9584\n",
      "Epoch: 253, Loss: 0.9527\n",
      "Epoch: 254, Loss: 0.9524\n",
      "Epoch: 255, Loss: 0.9573\n",
      "Epoch: 256, Loss: 0.9521\n",
      "Epoch: 257, Loss: 0.9518\n",
      "Epoch: 258, Loss: 0.9516\n",
      "Epoch: 259, Loss: 0.9514\n",
      "Epoch: 260, Loss: 0.9560\n",
      "Epoch: 261, Loss: 0.9554\n",
      "Epoch: 262, Loss: 0.9575\n",
      "Epoch: 263, Loss: 0.9506\n",
      "Epoch: 264, Loss: 0.9562\n",
      "Epoch: 265, Loss: 0.9502\n",
      "Epoch: 266, Loss: 0.9555\n",
      "Epoch: 267, Loss: 0.9498\n",
      "Epoch: 268, Loss: 0.9547\n",
      "Epoch: 269, Loss: 0.9540\n",
      "Epoch: 270, Loss: 0.9557\n",
      "Epoch: 271, Loss: 0.9548\n",
      "Epoch: 272, Loss: 0.9541\n",
      "Epoch: 273, Loss: 0.9489\n",
      "Epoch: 274, Loss: 0.9532\n",
      "Epoch: 275, Loss: 0.9486\n",
      "Epoch: 276, Loss: 0.9484\n",
      "Epoch: 277, Loss: 0.9481\n",
      "Epoch: 278, Loss: 0.9479\n",
      "Epoch: 279, Loss: 0.9522\n",
      "Epoch: 280, Loss: 0.9476\n",
      "Epoch: 281, Loss: 0.9517\n",
      "Epoch: 282, Loss: 0.9473\n",
      "Epoch: 283, Loss: 0.9471\n",
      "Epoch: 284, Loss: 0.9533\n",
      "Epoch: 285, Loss: 0.9518\n",
      "Epoch: 286, Loss: 0.9466\n",
      "Epoch: 287, Loss: 0.9465\n",
      "Epoch: 288, Loss: 0.9463\n",
      "Epoch: 289, Loss: 0.9519\n",
      "Epoch: 290, Loss: 0.9461\n",
      "Epoch: 291, Loss: 0.9460\n",
      "Epoch: 292, Loss: 0.9508\n",
      "Epoch: 293, Loss: 0.9502\n",
      "Epoch: 294, Loss: 0.9457\n",
      "Epoch: 295, Loss: 0.9454\n",
      "Epoch: 296, Loss: 0.9453\n",
      "Epoch: 297, Loss: 0.9517\n",
      "Epoch: 298, Loss: 0.9449\n",
      "Epoch: 299, Loss: 0.9499\n",
      "Epoch: 300, Loss: 0.9446\n",
      "Epoch: 301, Loss: 0.9506\n",
      "Epoch: 302, Loss: 0.9444\n",
      "Epoch: 303, Loss: 0.9499\n",
      "Epoch: 304, Loss: 0.9441\n",
      "Epoch: 305, Loss: 0.9498\n",
      "Epoch: 306, Loss: 0.9497\n",
      "Epoch: 307, Loss: 0.9437\n",
      "Epoch: 308, Loss: 0.9490\n",
      "Epoch: 309, Loss: 0.9484\n",
      "Epoch: 310, Loss: 0.9500\n",
      "Epoch: 311, Loss: 0.9433\n",
      "Epoch: 312, Loss: 0.9489\n",
      "Epoch: 313, Loss: 0.9483\n",
      "Epoch: 314, Loss: 0.9431\n",
      "Epoch: 315, Loss: 0.9475\n",
      "Epoch: 316, Loss: 0.9429\n",
      "Epoch: 317, Loss: 0.9427\n",
      "Epoch: 318, Loss: 0.9425\n",
      "Epoch: 319, Loss: 0.9489\n",
      "Epoch: 320, Loss: 0.9481\n",
      "Epoch: 321, Loss: 0.9480\n",
      "Epoch: 322, Loss: 0.9473\n",
      "Epoch: 323, Loss: 0.9419\n",
      "Epoch: 324, Loss: 0.9418\n",
      "Epoch: 325, Loss: 0.9467\n",
      "Epoch: 326, Loss: 0.9480\n",
      "Epoch: 327, Loss: 0.9472\n",
      "Epoch: 328, Loss: 0.9415\n",
      "Epoch: 329, Loss: 0.9414\n",
      "Epoch: 330, Loss: 0.9472\n",
      "Epoch: 331, Loss: 0.9465\n",
      "Epoch: 332, Loss: 0.9410\n",
      "Epoch: 333, Loss: 0.9409\n",
      "Epoch: 334, Loss: 0.9408\n",
      "Epoch: 335, Loss: 0.9467\n",
      "Epoch: 336, Loss: 0.9460\n",
      "Epoch: 337, Loss: 0.9407\n",
      "Epoch: 338, Loss: 0.9468\n",
      "Epoch: 339, Loss: 0.9457\n",
      "Epoch: 340, Loss: 0.9403\n",
      "Epoch: 341, Loss: 0.9451\n",
      "Epoch: 342, Loss: 0.9446\n",
      "Epoch: 343, Loss: 0.9441\n",
      "Epoch: 344, Loss: 0.9475\n",
      "Epoch: 345, Loss: 0.9441\n",
      "Epoch: 346, Loss: 0.9437\n",
      "Epoch: 347, Loss: 0.9470\n",
      "Epoch: 348, Loss: 0.9460\n",
      "Epoch: 349, Loss: 0.9453\n",
      "Epoch: 350, Loss: 0.9454\n",
      "Epoch: 351, Loss: 0.9448\n",
      "Epoch: 352, Loss: 0.9442\n",
      "Epoch: 353, Loss: 0.9394\n",
      "Epoch: 354, Loss: 0.9393\n",
      "Epoch: 355, Loss: 0.9435\n",
      "Epoch: 356, Loss: 0.9460\n",
      "Epoch: 357, Loss: 0.9389\n",
      "Epoch: 358, Loss: 0.9449\n",
      "Epoch: 359, Loss: 0.9442\n",
      "Epoch: 360, Loss: 0.9446\n",
      "Epoch: 361, Loss: 0.9439\n",
      "Epoch: 362, Loss: 0.9433\n",
      "Epoch: 363, Loss: 0.9447\n",
      "Epoch: 364, Loss: 0.9383\n",
      "Epoch: 365, Loss: 0.9382\n",
      "Epoch: 366, Loss: 0.9434\n",
      "Epoch: 367, Loss: 0.9381\n",
      "Epoch: 368, Loss: 0.9428\n",
      "Epoch: 369, Loss: 0.9380\n",
      "Epoch: 370, Loss: 0.9379\n",
      "Epoch: 371, Loss: 0.9378\n",
      "Epoch: 372, Loss: 0.9425\n",
      "Epoch: 373, Loss: 0.9377\n",
      "Epoch: 374, Loss: 0.9376\n",
      "Epoch: 375, Loss: 0.9422\n",
      "Epoch: 376, Loss: 0.9375\n",
      "Epoch: 377, Loss: 0.9438\n",
      "Epoch: 378, Loss: 0.9374\n",
      "Epoch: 379, Loss: 0.9426\n",
      "Epoch: 380, Loss: 0.9432\n",
      "Epoch: 381, Loss: 0.9427\n",
      "Epoch: 382, Loss: 0.9371\n",
      "Epoch: 383, Loss: 0.9370\n",
      "Epoch: 384, Loss: 0.9370\n",
      "Epoch: 385, Loss: 0.9425\n",
      "Epoch: 386, Loss: 0.9419\n",
      "Epoch: 387, Loss: 0.9369\n",
      "Epoch: 388, Loss: 0.9413\n",
      "Epoch: 389, Loss: 0.9369\n",
      "Epoch: 390, Loss: 0.9367\n",
      "Epoch: 391, Loss: 0.9432\n",
      "Epoch: 392, Loss: 0.9365\n",
      "Epoch: 393, Loss: 0.9423\n",
      "Epoch: 394, Loss: 0.9421\n",
      "Epoch: 395, Loss: 0.9363\n",
      "Epoch: 396, Loss: 0.9362\n",
      "Epoch: 397, Loss: 0.9416\n",
      "Epoch: 398, Loss: 0.9422\n",
      "Epoch: 399, Loss: 0.9415\n",
      "Epoch: 400, Loss: 0.9409\n",
      "Epoch: 401, Loss: 0.9404\n",
      "Epoch: 402, Loss: 0.9400\n",
      "Epoch: 403, Loss: 0.9396\n",
      "Epoch: 404, Loss: 0.9392\n",
      "Epoch: 405, Loss: 0.9360\n",
      "Epoch: 406, Loss: 0.9436\n",
      "Epoch: 407, Loss: 0.9426\n",
      "Epoch: 408, Loss: 0.9403\n",
      "Epoch: 409, Loss: 0.9419\n",
      "Epoch: 410, Loss: 0.9407\n",
      "Epoch: 411, Loss: 0.9414\n",
      "Epoch: 412, Loss: 0.9408\n",
      "Epoch: 413, Loss: 0.9417\n",
      "Epoch: 414, Loss: 0.9404\n",
      "Epoch: 415, Loss: 0.9354\n",
      "Epoch: 416, Loss: 0.9415\n",
      "Epoch: 417, Loss: 0.9402\n",
      "Epoch: 418, Loss: 0.9351\n",
      "Epoch: 419, Loss: 0.9351\n",
      "Epoch: 420, Loss: 0.9411\n",
      "Epoch: 421, Loss: 0.9404\n",
      "Epoch: 422, Loss: 0.9349\n",
      "Epoch: 423, Loss: 0.9407\n",
      "Epoch: 424, Loss: 0.9402\n",
      "Epoch: 425, Loss: 0.9406\n",
      "Epoch: 426, Loss: 0.9401\n",
      "Epoch: 427, Loss: 0.9396\n",
      "Epoch: 428, Loss: 0.9391\n",
      "Epoch: 429, Loss: 0.9386\n",
      "Epoch: 430, Loss: 0.9418\n",
      "Epoch: 431, Loss: 0.9345\n",
      "Epoch: 432, Loss: 0.9406\n",
      "Epoch: 433, Loss: 0.9395\n",
      "Epoch: 434, Loss: 0.9390\n",
      "Epoch: 435, Loss: 0.9406\n",
      "Epoch: 436, Loss: 0.9342\n",
      "Epoch: 437, Loss: 0.9393\n",
      "Epoch: 438, Loss: 0.9388\n",
      "Epoch: 439, Loss: 0.9341\n",
      "Epoch: 440, Loss: 0.9385\n",
      "Epoch: 441, Loss: 0.9340\n",
      "Epoch: 442, Loss: 0.9340\n",
      "Epoch: 443, Loss: 0.9339\n",
      "Epoch: 444, Loss: 0.9385\n",
      "Epoch: 445, Loss: 0.9338\n",
      "Epoch: 446, Loss: 0.9338\n",
      "Epoch: 447, Loss: 0.9338\n",
      "Epoch: 448, Loss: 0.9386\n",
      "Epoch: 449, Loss: 0.9337\n",
      "Epoch: 450, Loss: 0.9398\n",
      "Epoch: 451, Loss: 0.9390\n",
      "Epoch: 452, Loss: 0.9336\n",
      "Epoch: 453, Loss: 0.9386\n",
      "Epoch: 454, Loss: 0.9335\n",
      "Epoch: 455, Loss: 0.9382\n",
      "Epoch: 456, Loss: 0.9334\n",
      "Epoch: 457, Loss: 0.9334\n",
      "Epoch: 458, Loss: 0.9333\n",
      "Epoch: 459, Loss: 0.9381\n",
      "Epoch: 460, Loss: 0.9396\n",
      "Epoch: 461, Loss: 0.9389\n",
      "Epoch: 462, Loss: 0.9333\n",
      "Epoch: 463, Loss: 0.9382\n",
      "Epoch: 464, Loss: 0.9377\n",
      "Epoch: 465, Loss: 0.9333\n",
      "Epoch: 466, Loss: 0.9332\n",
      "Epoch: 467, Loss: 0.9331\n",
      "Epoch: 468, Loss: 0.9396\n",
      "Epoch: 469, Loss: 0.9378\n",
      "Epoch: 470, Loss: 0.9329\n",
      "Epoch: 471, Loss: 0.9391\n",
      "Epoch: 472, Loss: 0.9328\n",
      "Epoch: 473, Loss: 0.9328\n",
      "Epoch: 474, Loss: 0.9382\n",
      "Epoch: 475, Loss: 0.9376\n",
      "Epoch: 476, Loss: 0.9329\n",
      "Epoch: 477, Loss: 0.9328\n",
      "Epoch: 478, Loss: 0.9392\n",
      "Epoch: 479, Loss: 0.9384\n",
      "Epoch: 480, Loss: 0.9326\n",
      "Epoch: 481, Loss: 0.9378\n",
      "Epoch: 482, Loss: 0.9388\n",
      "Epoch: 483, Loss: 0.9324\n",
      "Epoch: 484, Loss: 0.9324\n",
      "Epoch: 485, Loss: 0.9324\n",
      "Epoch: 486, Loss: 0.9323\n",
      "Epoch: 487, Loss: 0.9379\n",
      "Epoch: 488, Loss: 0.9374\n",
      "Epoch: 489, Loss: 0.9323\n",
      "Epoch: 490, Loss: 0.9386\n",
      "Epoch: 491, Loss: 0.9374\n",
      "Epoch: 492, Loss: 0.9384\n",
      "Epoch: 493, Loss: 0.9321\n",
      "Epoch: 494, Loss: 0.9375\n",
      "Epoch: 495, Loss: 0.9321\n",
      "Epoch: 496, Loss: 0.9370\n",
      "Epoch: 497, Loss: 0.9320\n",
      "Epoch: 498, Loss: 0.9366\n",
      "Epoch: 499, Loss: 0.9387\n",
      "Epoch: 500, Loss: 0.9319\n",
      "Epoch: 501, Loss: 0.9369\n",
      "Epoch: 502, Loss: 0.9319\n",
      "Epoch: 503, Loss: 0.9380\n",
      "Epoch: 504, Loss: 0.9373\n",
      "Epoch: 505, Loss: 0.9377\n",
      "Epoch: 506, Loss: 0.9318\n",
      "Epoch: 507, Loss: 0.9318\n",
      "Epoch: 508, Loss: 0.9370\n",
      "Epoch: 509, Loss: 0.9381\n",
      "Epoch: 510, Loss: 0.9369\n",
      "Epoch: 511, Loss: 0.9317\n",
      "Epoch: 512, Loss: 0.9316\n",
      "Epoch: 513, Loss: 0.9364\n",
      "Epoch: 514, Loss: 0.9316\n",
      "Epoch: 515, Loss: 0.9315\n",
      "Epoch: 516, Loss: 0.9315\n",
      "Epoch: 517, Loss: 0.9314\n",
      "Epoch: 518, Loss: 0.9363\n",
      "Epoch: 519, Loss: 0.9314\n",
      "Epoch: 520, Loss: 0.9360\n",
      "Epoch: 521, Loss: 0.9313\n",
      "Epoch: 522, Loss: 0.9357\n",
      "Epoch: 523, Loss: 0.9383\n",
      "Epoch: 524, Loss: 0.9313\n",
      "Epoch: 525, Loss: 0.9312\n",
      "Epoch: 526, Loss: 0.9364\n",
      "Epoch: 527, Loss: 0.9312\n",
      "Epoch: 528, Loss: 0.9311\n",
      "Epoch: 529, Loss: 0.9311\n",
      "Epoch: 530, Loss: 0.9311\n",
      "Epoch: 531, Loss: 0.9365\n",
      "Epoch: 532, Loss: 0.9373\n",
      "Epoch: 533, Loss: 0.9311\n",
      "Epoch: 534, Loss: 0.9365\n",
      "Epoch: 535, Loss: 0.9374\n",
      "Epoch: 536, Loss: 0.9367\n",
      "Epoch: 537, Loss: 0.9368\n",
      "Epoch: 538, Loss: 0.9309\n",
      "Epoch: 539, Loss: 0.9362\n",
      "Epoch: 540, Loss: 0.9309\n",
      "Epoch: 541, Loss: 0.9357\n",
      "Epoch: 542, Loss: 0.9353\n",
      "Epoch: 543, Loss: 0.9349\n",
      "Epoch: 544, Loss: 0.9386\n",
      "Epoch: 545, Loss: 0.9308\n",
      "Epoch: 546, Loss: 0.9352\n",
      "Epoch: 547, Loss: 0.9377\n",
      "Epoch: 548, Loss: 0.9307\n",
      "Epoch: 549, Loss: 0.9367\n",
      "Epoch: 550, Loss: 0.9308\n",
      "Epoch: 551, Loss: 0.9366\n",
      "Epoch: 552, Loss: 0.9360\n",
      "Epoch: 553, Loss: 0.9306\n",
      "Epoch: 554, Loss: 0.9305\n",
      "Epoch: 555, Loss: 0.9357\n",
      "Epoch: 556, Loss: 0.9369\n",
      "Epoch: 557, Loss: 0.9305\n",
      "Epoch: 558, Loss: 0.9305\n",
      "Epoch: 559, Loss: 0.9305\n",
      "Epoch: 560, Loss: 0.9360\n",
      "Epoch: 561, Loss: 0.9367\n",
      "Epoch: 562, Loss: 0.9304\n",
      "Epoch: 563, Loss: 0.9303\n",
      "Epoch: 564, Loss: 0.9303\n",
      "Epoch: 565, Loss: 0.9358\n",
      "Epoch: 566, Loss: 0.9303\n",
      "Epoch: 567, Loss: 0.9365\n",
      "Epoch: 568, Loss: 0.9358\n",
      "Epoch: 569, Loss: 0.9353\n",
      "Epoch: 570, Loss: 0.9369\n",
      "Epoch: 571, Loss: 0.9302\n",
      "Epoch: 572, Loss: 0.9302\n",
      "Epoch: 573, Loss: 0.9355\n",
      "Epoch: 574, Loss: 0.9301\n",
      "Epoch: 575, Loss: 0.9350\n",
      "Epoch: 576, Loss: 0.9301\n",
      "Epoch: 577, Loss: 0.9301\n",
      "Epoch: 578, Loss: 0.9365\n",
      "Epoch: 579, Loss: 0.9358\n",
      "Epoch: 580, Loss: 0.9301\n",
      "Epoch: 581, Loss: 0.9362\n",
      "Epoch: 582, Loss: 0.9356\n",
      "Epoch: 583, Loss: 0.9299\n",
      "Epoch: 584, Loss: 0.9351\n",
      "Epoch: 585, Loss: 0.9299\n",
      "Epoch: 586, Loss: 0.9299\n",
      "Epoch: 587, Loss: 0.9299\n",
      "Epoch: 588, Loss: 0.9299\n",
      "Epoch: 589, Loss: 0.9298\n",
      "Epoch: 590, Loss: 0.9298\n",
      "Epoch: 591, Loss: 0.9298\n",
      "Epoch: 592, Loss: 0.9357\n",
      "Epoch: 593, Loss: 0.9298\n",
      "Epoch: 594, Loss: 0.9350\n",
      "Epoch: 595, Loss: 0.9299\n",
      "Epoch: 596, Loss: 0.9364\n",
      "Epoch: 597, Loss: 0.9297\n",
      "Epoch: 598, Loss: 0.9350\n",
      "Epoch: 599, Loss: 0.9362\n",
      "Epoch: 600, Loss: 0.9351\n",
      "Epoch: 601, Loss: 0.9360\n",
      "Epoch: 602, Loss: 0.9352\n",
      "Epoch: 603, Loss: 0.9358\n",
      "Epoch: 604, Loss: 0.9353\n",
      "Epoch: 605, Loss: 0.9348\n",
      "Epoch: 606, Loss: 0.9296\n",
      "Epoch: 607, Loss: 0.9343\n",
      "Epoch: 608, Loss: 0.9295\n",
      "Epoch: 609, Loss: 0.9295\n",
      "Epoch: 610, Loss: 0.9342\n",
      "Epoch: 611, Loss: 0.9338\n",
      "Epoch: 612, Loss: 0.9295\n",
      "Epoch: 613, Loss: 0.9366\n",
      "Epoch: 614, Loss: 0.9343\n",
      "Epoch: 615, Loss: 0.9339\n",
      "Epoch: 616, Loss: 0.9294\n",
      "Epoch: 617, Loss: 0.9362\n",
      "Epoch: 618, Loss: 0.9294\n",
      "Epoch: 619, Loss: 0.9348\n",
      "Epoch: 620, Loss: 0.9343\n",
      "Epoch: 621, Loss: 0.9293\n",
      "Epoch: 622, Loss: 0.9293\n",
      "Epoch: 623, Loss: 0.9356\n",
      "Epoch: 624, Loss: 0.9350\n",
      "Epoch: 625, Loss: 0.9353\n",
      "Epoch: 626, Loss: 0.9293\n",
      "Epoch: 627, Loss: 0.9346\n",
      "Epoch: 628, Loss: 0.9341\n",
      "Epoch: 629, Loss: 0.9366\n",
      "Epoch: 630, Loss: 0.9357\n",
      "Epoch: 631, Loss: 0.9345\n",
      "Epoch: 632, Loss: 0.9292\n",
      "Epoch: 633, Loss: 0.9291\n",
      "Epoch: 634, Loss: 0.9353\n",
      "Epoch: 635, Loss: 0.9346\n",
      "Epoch: 636, Loss: 0.9341\n",
      "Epoch: 637, Loss: 0.9360\n",
      "Epoch: 638, Loss: 0.9291\n",
      "Epoch: 639, Loss: 0.9341\n",
      "Epoch: 640, Loss: 0.9336\n",
      "Epoch: 641, Loss: 0.9291\n",
      "Epoch: 642, Loss: 0.9291\n",
      "Epoch: 643, Loss: 0.9290\n",
      "Epoch: 644, Loss: 0.9356\n",
      "Epoch: 645, Loss: 0.9290\n",
      "Epoch: 646, Loss: 0.9348\n",
      "Epoch: 647, Loss: 0.9291\n",
      "Epoch: 648, Loss: 0.9341\n",
      "Epoch: 649, Loss: 0.9336\n",
      "Epoch: 650, Loss: 0.9364\n",
      "Epoch: 651, Loss: 0.9289\n",
      "Epoch: 652, Loss: 0.9336\n",
      "Epoch: 653, Loss: 0.9289\n",
      "Epoch: 654, Loss: 0.9288\n",
      "Epoch: 655, Loss: 0.9288\n",
      "Epoch: 656, Loss: 0.9353\n",
      "Epoch: 657, Loss: 0.9288\n",
      "Epoch: 658, Loss: 0.9344\n",
      "Epoch: 659, Loss: 0.9287\n",
      "Epoch: 660, Loss: 0.9340\n",
      "Epoch: 661, Loss: 0.9287\n",
      "Epoch: 662, Loss: 0.9351\n",
      "Epoch: 663, Loss: 0.9344\n",
      "Epoch: 664, Loss: 0.9288\n",
      "Epoch: 665, Loss: 0.9338\n",
      "Epoch: 666, Loss: 0.9289\n",
      "Epoch: 667, Loss: 0.9333\n",
      "Epoch: 668, Loss: 0.9329\n",
      "Epoch: 669, Loss: 0.9365\n",
      "Epoch: 670, Loss: 0.9286\n",
      "Epoch: 671, Loss: 0.9286\n",
      "Epoch: 672, Loss: 0.9286\n",
      "Epoch: 673, Loss: 0.9335\n",
      "Epoch: 674, Loss: 0.9286\n",
      "Epoch: 675, Loss: 0.9351\n",
      "Epoch: 676, Loss: 0.9340\n",
      "Epoch: 677, Loss: 0.9335\n",
      "Epoch: 678, Loss: 0.9331\n",
      "Epoch: 679, Loss: 0.9327\n",
      "Epoch: 680, Loss: 0.9324\n",
      "Epoch: 681, Loss: 0.9321\n",
      "Epoch: 682, Loss: 0.9286\n",
      "Epoch: 683, Loss: 0.9285\n",
      "Epoch: 684, Loss: 0.9357\n",
      "Epoch: 685, Loss: 0.9349\n",
      "Epoch: 686, Loss: 0.9343\n",
      "Epoch: 687, Loss: 0.9285\n",
      "Epoch: 688, Loss: 0.9285\n",
      "Epoch: 689, Loss: 0.9341\n",
      "Epoch: 690, Loss: 0.9349\n",
      "Epoch: 691, Loss: 0.9284\n",
      "Epoch: 692, Loss: 0.9284\n",
      "Epoch: 693, Loss: 0.9337\n",
      "Epoch: 694, Loss: 0.9332\n",
      "Epoch: 695, Loss: 0.9328\n",
      "Epoch: 696, Loss: 0.9324\n",
      "Epoch: 697, Loss: 0.9287\n",
      "Epoch: 698, Loss: 0.9361\n",
      "Epoch: 699, Loss: 0.9326\n",
      "Epoch: 700, Loss: 0.9355\n",
      "Epoch: 701, Loss: 0.9346\n",
      "Epoch: 702, Loss: 0.9340\n",
      "Epoch: 703, Loss: 0.9347\n",
      "Epoch: 704, Loss: 0.9337\n",
      "Epoch: 705, Loss: 0.9284\n",
      "Epoch: 706, Loss: 0.9347\n",
      "Epoch: 707, Loss: 0.9282\n",
      "Epoch: 708, Loss: 0.9335\n",
      "Epoch: 709, Loss: 0.9330\n",
      "Epoch: 710, Loss: 0.9326\n",
      "Epoch: 711, Loss: 0.9284\n",
      "Epoch: 712, Loss: 0.9282\n",
      "Epoch: 713, Loss: 0.9323\n",
      "Epoch: 714, Loss: 0.9355\n",
      "Epoch: 715, Loss: 0.9346\n",
      "Epoch: 716, Loss: 0.9281\n",
      "Epoch: 717, Loss: 0.9336\n",
      "Epoch: 718, Loss: 0.9281\n",
      "Epoch: 719, Loss: 0.9281\n",
      "Epoch: 720, Loss: 0.9281\n",
      "Epoch: 721, Loss: 0.9338\n",
      "Epoch: 722, Loss: 0.9332\n",
      "Epoch: 723, Loss: 0.9349\n",
      "Epoch: 724, Loss: 0.9280\n",
      "Epoch: 725, Loss: 0.9341\n",
      "Epoch: 726, Loss: 0.9280\n",
      "Epoch: 727, Loss: 0.9280\n",
      "Epoch: 728, Loss: 0.9279\n",
      "Epoch: 729, Loss: 0.9335\n",
      "Epoch: 730, Loss: 0.9280\n",
      "Epoch: 731, Loss: 0.9330\n",
      "Epoch: 732, Loss: 0.9280\n",
      "Epoch: 733, Loss: 0.9280\n",
      "Epoch: 734, Loss: 0.9327\n",
      "Epoch: 735, Loss: 0.9280\n",
      "Epoch: 736, Loss: 0.9279\n",
      "Epoch: 737, Loss: 0.9345\n",
      "Epoch: 738, Loss: 0.9332\n",
      "Epoch: 739, Loss: 0.9278\n",
      "Epoch: 740, Loss: 0.9278\n",
      "Epoch: 741, Loss: 0.9278\n",
      "Epoch: 742, Loss: 0.9332\n",
      "Epoch: 743, Loss: 0.9327\n",
      "Epoch: 744, Loss: 0.9278\n",
      "Epoch: 745, Loss: 0.9278\n",
      "Epoch: 746, Loss: 0.9343\n",
      "Epoch: 747, Loss: 0.9333\n",
      "Epoch: 748, Loss: 0.9328\n",
      "Epoch: 749, Loss: 0.9278\n",
      "Epoch: 750, Loss: 0.9277\n",
      "Epoch: 751, Loss: 0.9327\n",
      "Epoch: 752, Loss: 0.9277\n",
      "Epoch: 753, Loss: 0.9343\n",
      "Epoch: 754, Loss: 0.9336\n",
      "Epoch: 755, Loss: 0.9279\n",
      "Epoch: 756, Loss: 0.9329\n",
      "Epoch: 757, Loss: 0.9324\n",
      "Epoch: 758, Loss: 0.9353\n",
      "Epoch: 759, Loss: 0.9277\n",
      "Epoch: 760, Loss: 0.9343\n",
      "Epoch: 761, Loss: 0.9276\n",
      "Epoch: 762, Loss: 0.9331\n",
      "Epoch: 763, Loss: 0.9326\n",
      "Epoch: 764, Loss: 0.9277\n",
      "Epoch: 765, Loss: 0.9276\n",
      "Epoch: 766, Loss: 0.9324\n",
      "Epoch: 767, Loss: 0.9346\n",
      "Epoch: 768, Loss: 0.9276\n",
      "Epoch: 769, Loss: 0.9328\n",
      "Epoch: 770, Loss: 0.9276\n",
      "Epoch: 771, Loss: 0.9325\n",
      "Epoch: 772, Loss: 0.9321\n",
      "Epoch: 773, Loss: 0.9276\n",
      "Epoch: 774, Loss: 0.9275\n",
      "Epoch: 775, Loss: 0.9275\n",
      "Epoch: 776, Loss: 0.9275\n",
      "Epoch: 777, Loss: 0.9338\n",
      "Epoch: 778, Loss: 0.9332\n",
      "Epoch: 779, Loss: 0.9277\n",
      "Epoch: 780, Loss: 0.9325\n",
      "Epoch: 781, Loss: 0.9278\n",
      "Epoch: 782, Loss: 0.9277\n",
      "Epoch: 783, Loss: 0.9345\n",
      "Epoch: 784, Loss: 0.9337\n",
      "Epoch: 785, Loss: 0.9332\n",
      "Epoch: 786, Loss: 0.9326\n",
      "Epoch: 787, Loss: 0.9340\n",
      "Epoch: 788, Loss: 0.9274\n",
      "Epoch: 789, Loss: 0.9274\n",
      "Epoch: 790, Loss: 0.9329\n",
      "Epoch: 791, Loss: 0.9337\n",
      "Epoch: 792, Loss: 0.9330\n",
      "Epoch: 793, Loss: 0.9275\n",
      "Epoch: 794, Loss: 0.9325\n",
      "Epoch: 795, Loss: 0.9275\n",
      "Epoch: 796, Loss: 0.9342\n",
      "Epoch: 797, Loss: 0.9325\n",
      "Epoch: 798, Loss: 0.9274\n",
      "Epoch: 799, Loss: 0.9273\n",
      "Epoch: 800, Loss: 0.9337\n",
      "Epoch: 801, Loss: 0.9330\n",
      "Epoch: 802, Loss: 0.9274\n",
      "Epoch: 803, Loss: 0.9274\n",
      "Epoch: 804, Loss: 0.9273\n",
      "Epoch: 805, Loss: 0.9336\n",
      "Epoch: 806, Loss: 0.9273\n",
      "Epoch: 807, Loss: 0.9273\n",
      "Epoch: 808, Loss: 0.9329\n",
      "Epoch: 809, Loss: 0.9324\n",
      "Epoch: 810, Loss: 0.9273\n",
      "Epoch: 811, Loss: 0.9273\n",
      "Epoch: 812, Loss: 0.9339\n",
      "Epoch: 813, Loss: 0.9326\n",
      "Epoch: 814, Loss: 0.9272\n",
      "Epoch: 815, Loss: 0.9272\n",
      "Epoch: 816, Loss: 0.9272\n",
      "Epoch: 817, Loss: 0.9272\n",
      "Epoch: 818, Loss: 0.9332\n",
      "Epoch: 819, Loss: 0.9333\n",
      "Epoch: 820, Loss: 0.9331\n",
      "Epoch: 821, Loss: 0.9333\n",
      "Epoch: 822, Loss: 0.9272\n",
      "Epoch: 823, Loss: 0.9328\n",
      "Epoch: 824, Loss: 0.9322\n",
      "Epoch: 825, Loss: 0.9340\n",
      "Epoch: 826, Loss: 0.9271\n",
      "Epoch: 827, Loss: 0.9324\n",
      "Epoch: 828, Loss: 0.9271\n",
      "Epoch: 829, Loss: 0.9321\n",
      "Epoch: 830, Loss: 0.9271\n",
      "Epoch: 831, Loss: 0.9338\n",
      "Epoch: 832, Loss: 0.9325\n",
      "Epoch: 833, Loss: 0.9271\n",
      "Epoch: 834, Loss: 0.9271\n",
      "Epoch: 835, Loss: 0.9323\n",
      "Epoch: 836, Loss: 0.9271\n",
      "Epoch: 837, Loss: 0.9335\n",
      "Epoch: 838, Loss: 0.9271\n",
      "Epoch: 839, Loss: 0.9271\n",
      "Epoch: 840, Loss: 0.9327\n",
      "Epoch: 841, Loss: 0.9336\n",
      "Epoch: 842, Loss: 0.9326\n",
      "Epoch: 843, Loss: 0.9271\n",
      "Epoch: 844, Loss: 0.9271\n",
      "Epoch: 845, Loss: 0.9321\n",
      "Epoch: 846, Loss: 0.9271\n",
      "Epoch: 847, Loss: 0.9317\n",
      "Epoch: 848, Loss: 0.9271\n",
      "Epoch: 849, Loss: 0.9270\n",
      "Epoch: 850, Loss: 0.9315\n",
      "Epoch: 851, Loss: 0.9270\n",
      "Epoch: 852, Loss: 0.9313\n",
      "Epoch: 853, Loss: 0.9310\n",
      "Epoch: 854, Loss: 0.9307\n",
      "Epoch: 855, Loss: 0.9350\n",
      "Epoch: 856, Loss: 0.9313\n",
      "Epoch: 857, Loss: 0.9343\n",
      "Epoch: 858, Loss: 0.9335\n",
      "Epoch: 859, Loss: 0.9328\n",
      "Epoch: 860, Loss: 0.9274\n",
      "Epoch: 861, Loss: 0.9338\n",
      "Epoch: 862, Loss: 0.9270\n",
      "Epoch: 863, Loss: 0.9322\n",
      "Epoch: 864, Loss: 0.9271\n",
      "Epoch: 865, Loss: 0.9337\n",
      "Epoch: 866, Loss: 0.9329\n",
      "Epoch: 867, Loss: 0.9328\n",
      "Epoch: 868, Loss: 0.9269\n",
      "Epoch: 869, Loss: 0.9322\n",
      "Epoch: 870, Loss: 0.9269\n",
      "Epoch: 871, Loss: 0.9333\n",
      "Epoch: 872, Loss: 0.9326\n",
      "Epoch: 873, Loss: 0.9269\n",
      "Epoch: 874, Loss: 0.9320\n",
      "Epoch: 875, Loss: 0.9337\n",
      "Epoch: 876, Loss: 0.9268\n",
      "Epoch: 877, Loss: 0.9268\n",
      "Epoch: 878, Loss: 0.9321\n",
      "Epoch: 879, Loss: 0.9334\n",
      "Epoch: 880, Loss: 0.9327\n",
      "Epoch: 881, Loss: 0.9321\n",
      "Epoch: 882, Loss: 0.9269\n",
      "Epoch: 883, Loss: 0.9316\n",
      "Epoch: 884, Loss: 0.9340\n",
      "Epoch: 885, Loss: 0.9268\n",
      "Epoch: 886, Loss: 0.9268\n",
      "Epoch: 887, Loss: 0.9267\n",
      "Epoch: 888, Loss: 0.9267\n",
      "Epoch: 889, Loss: 0.9267\n",
      "Epoch: 890, Loss: 0.9267\n",
      "Epoch: 891, Loss: 0.9322\n",
      "Epoch: 892, Loss: 0.9267\n",
      "Epoch: 893, Loss: 0.9330\n",
      "Epoch: 894, Loss: 0.9267\n",
      "Epoch: 895, Loss: 0.9326\n",
      "Epoch: 896, Loss: 0.9328\n",
      "Epoch: 897, Loss: 0.9327\n",
      "Epoch: 898, Loss: 0.9267\n",
      "Epoch: 899, Loss: 0.9321\n",
      "Epoch: 900, Loss: 0.9267\n",
      "Epoch: 901, Loss: 0.9267\n",
      "Epoch: 902, Loss: 0.9318\n",
      "Epoch: 903, Loss: 0.9267\n",
      "Epoch: 904, Loss: 0.9315\n",
      "Epoch: 905, Loss: 0.9311\n",
      "Epoch: 906, Loss: 0.9267\n",
      "Epoch: 907, Loss: 0.9339\n",
      "Epoch: 908, Loss: 0.9331\n",
      "Epoch: 909, Loss: 0.9324\n",
      "Epoch: 910, Loss: 0.9269\n",
      "Epoch: 911, Loss: 0.9268\n",
      "Epoch: 912, Loss: 0.9332\n",
      "Epoch: 913, Loss: 0.9321\n",
      "Epoch: 914, Loss: 0.9267\n",
      "Epoch: 915, Loss: 0.9266\n",
      "Epoch: 916, Loss: 0.9330\n",
      "Epoch: 917, Loss: 0.9266\n",
      "Epoch: 918, Loss: 0.9266\n",
      "Epoch: 919, Loss: 0.9266\n",
      "Epoch: 920, Loss: 0.9266\n",
      "Epoch: 921, Loss: 0.9323\n",
      "Epoch: 922, Loss: 0.9328\n",
      "Epoch: 923, Loss: 0.9322\n",
      "Epoch: 924, Loss: 0.9266\n",
      "Epoch: 925, Loss: 0.9330\n",
      "Epoch: 926, Loss: 0.9265\n",
      "Epoch: 927, Loss: 0.9322\n",
      "Epoch: 928, Loss: 0.9328\n",
      "Epoch: 929, Loss: 0.9265\n",
      "Epoch: 930, Loss: 0.9323\n",
      "Epoch: 931, Loss: 0.9327\n",
      "Epoch: 932, Loss: 0.9265\n",
      "Epoch: 933, Loss: 0.9265\n",
      "Epoch: 934, Loss: 0.9265\n",
      "Epoch: 935, Loss: 0.9265\n",
      "Epoch: 936, Loss: 0.9265\n",
      "Epoch: 937, Loss: 0.9324\n",
      "Epoch: 938, Loss: 0.9318\n",
      "Epoch: 939, Loss: 0.9333\n",
      "Epoch: 940, Loss: 0.9318\n",
      "Epoch: 941, Loss: 0.9331\n",
      "Epoch: 942, Loss: 0.9320\n",
      "Epoch: 943, Loss: 0.9329\n",
      "Epoch: 944, Loss: 0.9265\n",
      "Epoch: 945, Loss: 0.9322\n",
      "Epoch: 946, Loss: 0.9264\n",
      "Epoch: 947, Loss: 0.9264\n",
      "Epoch: 948, Loss: 0.9318\n",
      "Epoch: 949, Loss: 0.9264\n",
      "Epoch: 950, Loss: 0.9314\n",
      "Epoch: 951, Loss: 0.9265\n",
      "Epoch: 952, Loss: 0.9264\n",
      "Epoch: 953, Loss: 0.9312\n",
      "Epoch: 954, Loss: 0.9308\n",
      "Epoch: 955, Loss: 0.9305\n",
      "Epoch: 956, Loss: 0.9343\n",
      "Epoch: 957, Loss: 0.9333\n",
      "Epoch: 958, Loss: 0.9317\n",
      "Epoch: 959, Loss: 0.9313\n",
      "Epoch: 960, Loss: 0.9264\n",
      "Epoch: 961, Loss: 0.9264\n",
      "Epoch: 962, Loss: 0.9328\n",
      "Epoch: 963, Loss: 0.9322\n",
      "Epoch: 964, Loss: 0.9264\n",
      "Epoch: 965, Loss: 0.9318\n",
      "Epoch: 966, Loss: 0.9264\n",
      "Epoch: 967, Loss: 0.9315\n",
      "Epoch: 968, Loss: 0.9263\n",
      "Epoch: 969, Loss: 0.9329\n",
      "Epoch: 970, Loss: 0.9320\n",
      "Epoch: 971, Loss: 0.9315\n",
      "Epoch: 972, Loss: 0.9310\n",
      "Epoch: 973, Loss: 0.9264\n",
      "Epoch: 974, Loss: 0.9332\n",
      "Epoch: 975, Loss: 0.9263\n",
      "Epoch: 976, Loss: 0.9263\n",
      "Epoch: 977, Loss: 0.9322\n",
      "Epoch: 978, Loss: 0.9326\n",
      "Epoch: 979, Loss: 0.9320\n",
      "Epoch: 980, Loss: 0.9315\n",
      "Epoch: 981, Loss: 0.9310\n",
      "Epoch: 982, Loss: 0.9266\n",
      "Epoch: 983, Loss: 0.9265\n",
      "Epoch: 984, Loss: 0.9264\n",
      "Epoch: 985, Loss: 0.9307\n",
      "Epoch: 986, Loss: 0.9263\n",
      "Epoch: 987, Loss: 0.9334\n",
      "Epoch: 988, Loss: 0.9326\n",
      "Epoch: 989, Loss: 0.9320\n",
      "Epoch: 990, Loss: 0.9265\n",
      "Epoch: 991, Loss: 0.9329\n",
      "Epoch: 992, Loss: 0.9322\n",
      "Epoch: 993, Loss: 0.9316\n",
      "Epoch: 994, Loss: 0.9263\n",
      "Epoch: 995, Loss: 0.9326\n",
      "Epoch: 996, Loss: 0.9262\n",
      "Epoch: 997, Loss: 0.9319\n",
      "Epoch: 998, Loss: 0.9324\n",
      "Epoch: 999, Loss: 0.9320\n",
      "Epoch: 1000, Loss: 0.9315\n"
     ]
    }
   ],
   "source": [
    "def loss_func(out, contexts):\n",
    "    out = nn.Softmax(dim=2)(out)\n",
    "    loss = torch.sum(torch.log(out) * contexts, dim=2)\n",
    "    loss = torch.sum(loss, dim=1)\n",
    "    loss = -torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(target, contexts)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "batch_size = 3\n",
    "skip_gram = Skip_gram(len(word_to_id), 3).to(device)\n",
    "optimizer = torch.optim.Adam(skip_gram.parameters(), lr=lr)\n",
    "loss_fn = loss_func\n",
    "\n",
    "hist_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = skip_gram(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    hist_loss.append(total_loss)\n",
    "    print('Epoch: {}, Loss: {:.4f}'.format(epoch+1, total_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2],\n",
      "        [1, 3],\n",
      "        [2, 4],\n",
      "        [3, 1],\n",
      "        [0, 2],\n",
      "        [1, 6]])\n",
      "tensor([[0, 2],\n",
      "        [1, 3],\n",
      "        [2, 4],\n",
      "        [3, 1],\n",
      "        [4, 5],\n",
      "        [1, 6]])\n"
     ]
    }
   ],
   "source": [
    "skip_gram.eval()\n",
    "\n",
    "h = skip_gram(target)\n",
    "h = nn.Softmax(dim=2)(h)\n",
    "ids = torch.argmax(h, dim=2)\n",
    "print(ids)\n",
    "contexts_ids = torch.argmax(contexts, dim=2)\n",
    "print(contexts_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddingレイヤの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utills import *\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW_embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, window_size=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.in_layer = nn.Embedding(vocab_size, hidden_size) # #mbedding層\n",
    "        self.out_layer = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, contexts):\n",
    "        # contexts: (batch_size, window_size*2)\n",
    "        h = self.in_layer(contexts) # (batch_size, window_size*2, hidden_size)\n",
    "        h = torch.mean(h, dim=1) # (batch_size, hidden_size)\n",
    "        # out = self.out_layer(h) # (batch_size, vocab_size)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = CBOW_embedding(len(word_to_id), 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "print(contexts)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = torch.tensor(contexts, dtype=torch.long).to(device)\n",
    "target = torch.tensor(target, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0035, -0.7420,  0.3500],\n",
       "        [ 0.8095, -0.4387, -0.8171],\n",
       "        [-0.5953, -0.4957, -0.9881],\n",
       "        [ 0.8095, -0.4387, -0.8171],\n",
       "        [-0.1139, -0.3172, -0.8481],\n",
       "        [ 0.2144, -0.7447,  0.4828]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW_embedding_negative(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, window_size=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.in_layer = nn.Embedding(vocab_size, hidden_size) # embedding層: (vocab_size, hidden_size)\n",
    "        self.out_layer = nn.Embedding(vocab_size, hidden_size) # embedding層: (vocab_size, hidden_size)\n",
    "\n",
    "    def forward(self, contexts, positive, negative):\n",
    "        # contexts: (batch_size, window_size*2)\n",
    "        h = self.in_layer(contexts) # (batch_size, window_size*2, hidden_size)\n",
    "        h = torch.mean(h, dim=1) # (batch_size, hidden_size)\n",
    "        out_positive = self.out_layer(positive) # (batch_size, hidden_size)\n",
    "        out_negative = self.out_layer(negative) # (batch_size, negative_size, hidden_size)\n",
    "\n",
    "        out_positive = torch.sum(h * out_positive, dim=1) # (batch_size): 内積\n",
    "        out_negative = torch.sum(h.unsqueeze(1) * out_negative, dim=2) # (batch_size, negative_size): 内積\n",
    "        return out_positive, out_negative\n",
    "    \n",
    "    def get_embedding(self):\n",
    "        return self.in_layer.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 77],\n",
       "        [14, 77]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]]).to(device)\n",
    "t2 = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [4, 5, 6]]]).to(device)\n",
    "\n",
    "torch.sum(t1 * t2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class negative_sampling:\n",
    "    def __init__(self, corpus, power=0.75, sample_size=5):\n",
    "        self.corpus = corpus # 単語IDのリスト\n",
    "        self.power = power\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self.idx, self.count = np.unique(corpus, return_counts=True) # 単語の出現回数\n",
    "        self.p = self.count / np.sum(self.count) # 単語の出現確率\n",
    "        self.p = self.p ** self.power / np.sum(self.p ** self.power) # 負例の確率分布\n",
    "    \n",
    "    def get_negative_sample(self, target):\n",
    "        batsch_size = len(target)\n",
    "        negative_sample = np.zeros((batsch_size, self.sample_size), dtype=np.int32)\n",
    "        for i in range(batsch_size):\n",
    "            p = self.p.copy()\n",
    "            target_idx = target[i]\n",
    "            p[target_idx] = 0\n",
    "            p /= p.sum()\n",
    "            negative_sample[i, :] = np.random.choice(self.idx, size=self.sample_size, replace=False, p=p)\n",
    "        return negative_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daiki\\AppData\\Local\\Temp\\ipykernel_23492\\2473442462.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive = torch.tensor(target, dtype=torch.long).to(device)\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "negative_sampler = negative_sampling(corpus)\n",
    "negative_sample = negative_sampler.get_negative_sample(target)\n",
    "\n",
    "contexts = torch.tensor(contexts, dtype=torch.long).to(device)\n",
    "target = torch.tensor(target, dtype=torch.long).to(device)\n",
    "negative = torch.tensor(negative_sample, dtype=torch.long).to(device)\n",
    "positive = torch.tensor(target, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = CBOW_embedding_negative(len(word_to_id), 3).to(device)\n",
    "\n",
    "out_positive, out_negative = cbow(contexts, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.6938, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.sigmoid(out_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(out_positive, out_negative):\n",
    "    out_positive = torch.sigmoid(out_positive) # (batch_size)\n",
    "    out_negative = torch.sigmoid(out_negative) # (batch_size, sample_size)\n",
    "    loss = -torch.sum(torch.log(out_positive)) - torch.sum(torch.log(1 - out_negative), dim=1)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss: 1.81\n",
      "epoch: 200, loss: 1.53\n",
      "epoch: 300, loss: 1.58\n",
      "epoch: 400, loss: 1.52\n",
      "epoch: 500, loss: 1.53\n",
      "epoch: 600, loss: 1.53\n",
      "epoch: 700, loss: 0.96\n",
      "epoch: 800, loss: 0.96\n",
      "epoch: 900, loss: 1.53\n",
      "epoch: 1000, loss: 1.52\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "negative_sampler = negative_sampling(corpus)\n",
    "negative_sample = negative_sampler.get_negative_sample(target)\n",
    "\n",
    "contexts = torch.tensor(contexts, dtype=torch.long).to(device)\n",
    "positive = torch.tensor(target, dtype=torch.long).to(device)\n",
    "\n",
    "cbow = CBOW_embedding_negative(len(word_to_id), 3).to(device)\n",
    "lr = 0.05\n",
    "epochs = 1000\n",
    "batch_size = 3\n",
    "optimizer = torch.optim.Adam(cbow.parameters(), lr=lr)\n",
    "loss_fn = loss_func\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(contexts, positive)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "hist_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (contexts, positive) in enumerate(loader):\n",
    "        negative_sample = negative_sampler.get_negative_sample(positive)\n",
    "        negative = torch.tensor(negative_sample, dtype=torch.long).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_positive, out_negative = cbow(contexts, positive, negative)\n",
    "        loss = loss_fn(out_positive, out_negative)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    hist_loss.append(running_loss)\n",
    "    if epoch % 100 == 99:\n",
    "        print(f'epoch: {epoch+1}, loss: {running_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.962084  ,  2.8039944 ,  2.9225554 ],\n",
       "       [ 0.59344816,  3.5227647 , -0.8129722 ],\n",
       "       [ 1.6782836 ,  2.5621574 ,  3.4552286 ],\n",
       "       [ 2.0984256 ,  1.7116871 ,  0.31451216],\n",
       "       [ 0.51081467,  2.900489  ,  4.9556127 ],\n",
       "       [-5.505786  ,  2.459367  ,  1.1749018 ],\n",
       "       [-4.999139  ,  5.454779  , -3.112235  ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow.get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skip_gram(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, window_size=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.in_layer = nn.Linear(vocab_size, hidden_size, bias=False)\n",
    "        self.out_layers = nn.ModuleList([nn.Linear(hidden_size, vocab_size, bias=False) for _ in range(window_size*2)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.in_layer(x)\n",
    "        outs = torch.zeros(self.window_size*2, x.size(0), self.vocab_size).to(device)\n",
    "\n",
    "        for i in range(self.window_size*2):\n",
    "            outs[i] = self.out_layers[i](h)\n",
    "        \n",
    "        outs = outs.permute(1, 0, 2)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skip_gram(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, window_size=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.in_layer = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.out_layers = nn.ModuleList([nn.Embedding(vocab_size, hidden_size) for _ in range(window_size*2)])\n",
    "\n",
    "    def forward(self, x, positive, negative):\n",
    "        h = self.in_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW_embedding_negative(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, window_size=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.in_layer = nn.Embedding(vocab_size, hidden_size) # embedding層: (vocab_size, hidden_size)\n",
    "        self.out_layer = nn.Embedding(vocab_size, hidden_size) # embedding層: (vocab_size, hidden_size)\n",
    "\n",
    "    def forward(self, contexts, positive, negative):\n",
    "        # contexts: (batch_size, window_size*2)\n",
    "        h = self.in_layer(contexts) # (batch_size, window_size*2, hidden_size)\n",
    "        h = torch.mean(h, dim=1) # (batch_size, hidden_size)\n",
    "        out_positive = self.out_layer(positive) # (batch_size, hidden_size)\n",
    "        out_negative = self.out_layer(negative) # (batch_size, negative_size, hidden_size)\n",
    "\n",
    "        out_positive = torch.sum(h * out_positive, dim=1) # (batch_size): 内積\n",
    "        out_negative = torch.sum(h.unsqueeze(1) * out_negative, dim=2) # (batch_size, negative_size): 内積\n",
    "        return out_positive, out_negative\n",
    "    \n",
    "    def get_embedding(self):\n",
    "        return self.in_layer.weight.data.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch_world_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
